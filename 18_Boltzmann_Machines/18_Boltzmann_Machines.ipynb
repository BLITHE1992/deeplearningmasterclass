{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "colab": {
      "name": "18_Boltzmann_Machines.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zg2c3t118Ou8"
      },
      "source": [
        "# **RESTRICTED BOLTZMANN MACHINES**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qzkneIhc8Ou9"
      },
      "source": [
        "### **Introduction**\n",
        "<b>Restricted Boltzmann Machine (RBM):</b>  RBMs are shallow neural nets that learn to reconstruct data by themselves in an unsupervised fashion.  \n",
        "\n",
        "#### **Why are RBMs important?**\n",
        "An RBM are a basic form of autoencoder.  It can automatically extract <b>meaningful</b> features from a given input.\n",
        "\n",
        "## **How does it work?**\n",
        "RBM is a 2 layer neural network. Simply, RBM takes the inputs and translates those into a set of binary values that represents them in the hidden layer. Then, these numbers can be translated back to reconstruct the inputs. Through several forward and backward passes, the RBM will be trained, and a trained RBM can reveal which features are the most important ones when detecting patterns.   \n",
        "\n",
        "**What are the applications of an RBM?**\n",
        "RBM is useful for <a href='http://www.cs.utoronto.ca/~hinton/absps/netflixICML.pdf'>  Collaborative Filtering</a>, dimensionality reduction, classification, regression, feature learning, topic modeling and even <b>Deep Belief Networks</b>.\n",
        "\n",
        "**Is RBM a generative or Discriminative model?**\n",
        "\n",
        "RBM is a generative model. Let me explain it by first, see what is different between discriminative and generative models: \n",
        "\n",
        "<b>Discriminative:</b> Consider a classification problem where we want to learn to distinguish between Sedan cars (y = 1) and SUV cars (y = 0), based on some features of cars. Given a training set, an algorithm like logistic regression tries to find a straight line, or <i>decision boundary</i>, that separates the suv and sedan.  \n",
        "\n",
        "<b>Generative:</b> looking at cars, we can build a model of what Sedan cars look like. Then, looking at SUVs, we can build a separate model of what SUV cars look like. Finally, to classify a new car, we can match the new car against the Sedan model, and match it against the SUV model, to see whether the new car looks more like the SUV or Sedan. \n",
        "\n",
        "Generative Models specify a probability distribution over a dataset of input vectors. We can carry out both supervised and unsupervised tasks with generative models:\n",
        "\n",
        "* In an unsupervised task, we try to form a model for $P(x)$, where $P$ is the probability given $x$ as an input vector.</\n",
        "\n",
        "* In the supervised task, we first form a model for $P(x|y)$, where $P$ is the probability of $x$ given $y$(the label for $x$). \n",
        "\n",
        "For example, if $y = 0$ indicates that a car is an SUV, and $y = 1$ indicates that a car is a sedan, then $p(x|y = 0)$ models the distribution of SUV features, and $p(x|y = 1)$ models the distribution of sedan features. If we manage to find $P(x|y)$ and $P(y)$, then we can use <b>Bayes rule</b> to estimate $P(y|x)$, because:   \n",
        "        $$p(y|x) = \\frac{p(x|y)p(y)}{p(x)}$$\n",
        "\n",
        "\n",
        "\n",
        "Now the question is, can we build a generative model, and then use it to create synthetic data by directly sampling from the modeled probability distributions? Lets see. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "URSuOhOh8Ou-"
      },
      "source": [
        "<h2>Table of Contents</h2>\n",
        "<ol>\n",
        "    <li><a href=\"#ref1\">Initialization</a></li>\n",
        "    <li><a href=\"#ref2\">RBM layers</a></li>\n",
        "    <li><a href=\"#ref3\">What RBM can do after training?</a></li>\n",
        "    <li><a href=\"#ref4\">How to train the model?</a></li>\n",
        "    <li><a href=\"#ref5\">Learned features</a></li>\n",
        "</ol>\n",
        "<p></p>\n",
        "</div>\n",
        "<br>\n",
        "\n",
        "<hr>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aDMox4Dq8Ou-"
      },
      "source": [
        "### **Installing TensorFlow**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TEVMgKjU8Ou_",
        "outputId": "42b97c29-1c2d-405c-f363-5b8ef77de40a"
      },
      "source": [
        "!pip install grpcio\n",
        "!pip install tensorflow\n",
        "!pip install pillow"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: grpcio in /usr/local/lib/python3.6/dist-packages (1.32.0)\n",
            "Requirement already satisfied: six>=1.5.2 in /usr/local/lib/python3.6/dist-packages (from grpcio) (1.15.0)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.6/dist-packages (2.4.0)\n",
            "Requirement already satisfied: h5py~=2.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (2.10.0)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.12.1)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.36.2)\n",
            "Requirement already satisfied: tensorboard~=2.4 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.7.4.3)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.2)\n",
            "Requirement already satisfied: grpcio~=1.32.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.32.0)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.12.4)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.3.3)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.12)\n",
            "Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.10.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.5.0,>=2.4.0rc0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: numpy~=1.19.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.19.4)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow) (0.4.2)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow) (2.23.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow) (3.3.3)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow) (51.0.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow) (1.7.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow) (1.17.2)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow) (1.3.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (2020.12.5)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard~=2.4->tensorflow) (3.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow) (4.6)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow) (4.2.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow) (3.1.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard~=2.4->tensorflow) (3.4.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3\"->google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (7.0.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O1Q1IzfL8Ou_"
      },
      "source": [
        "Now, we load in all the packages that we use to create the net including the TensorFlow package:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-TJqWS8U8OvA"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vwz6I0uj8OvA"
      },
      "source": [
        "<hr>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mfm7IJaF8OvA"
      },
      "source": [
        "<a id=\"ref2\"></a>\n",
        "\n",
        "<h3>RBM layers</h3>\n",
        "\n",
        "An RBM has two layers. The first layer of the RBM is called the <b>visible</b> (or input layer). Imagine we've only vectors with 7 values, so the visible layer must have $V=7$ input nodes. \n",
        "The second layer is the <b>hidden</b> layer, which has $H$ neurons in our case. Each hidden node takes on values of either 0 or 1 (i.e., $h_i = 1$ or $h_i$ = 0), with a probability that is a logistic function of the inputs it receives from the other $V$ visible units, called for example, $p(h_i = 1)$. For our  sample, we'll use 2 nodes in the hidden layer, so $H = 2$.\n",
        "\n",
        "<center><img src=\"https://ibm.box.com/shared/static/eu26opvcefgls6vnwuo29uwp0nudmokh.png\" alt=\"RBM Model\" style=\"width: 400px;\"></center>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1fbO07ic8OvA"
      },
      "source": [
        "Each node in the first layer also has a <b>bias</b>. We will denote the bias as $v_{bias}$, and this single value is shared among the $V$ visible units.\n",
        "\n",
        "The <b>bias</b> of the second is defined similarly as $h_{bias}$, and this single value among the $H$ hidden units.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9QMCMg8M8OvA"
      },
      "source": [
        "v_bias = tf.Variable(tf.zeros([7]), tf.float32)\n",
        "h_bias = tf.Variable(tf.zeros([2]), tf.float32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5hCyeYRl8OvA"
      },
      "source": [
        "We have to define weights among the input layer and hidden layer nodes. In the weight matrix, the number of rows are equal to the input nodes, and the number of columns are equal to the output nodes. We define a tensor $\\mathbf{W}$ of shape = (7,2), where the number of visible neurons = 7, and the number of hidden neurons = 2. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d7o3SXSs8OvB"
      },
      "source": [
        "W = tf.constant(np.random.normal(loc=0.0, scale=1.0, size=(7, 2)).astype(np.float32))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QTSn0fsB8OvB"
      },
      "source": [
        "<hr>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TWKJzP298OvB"
      },
      "source": [
        "<a id=\"ref3\"></a>\n",
        "\n",
        "**What RBM can do after training?**\n",
        "\n",
        "Think of RBM as a model that has been trained based on images of a dataset of many SUV and sedan cars. Also, imagine that the RBM network has only two hidden nodes, where one node encodes the weight and, and the other encodes the size.  \n",
        "In a sense, the different configurations represent different cars, where one is an SUV and the other is Sedan.  In a training process, through many forward and backward passes, the RBM adjust its weights to send a stronger signal to either the SUV node (0, 1) or the sedan node (1, 0) in the hidden layer, given the pixels of images. Now, given an SUV in hidden layer, which distribution of pixels should we expect? RBM can give you 2 things. First, it encodes your images in hidden layer. Second, it gives you the probability of observing a case, given some hidden values.\n",
        "\n",
        "<h3>The Inference Process</h3>\n",
        "\n",
        "RBM has two phases:\n",
        "\n",
        "<ul>\n",
        "    <li>Forward Pass</li>  \n",
        "    <li>Backward Pass or Reconstruction</li>\n",
        "</ul>\n",
        "\n",
        "<b>Phase 1) Forward pass:</b>  \n",
        "\n",
        "Input one training sample (one image) $\\mathbf{x}$ through all visible nodes, and pass it to all hidden nodes. Processing happens in each node in the hidden layer. This computation begins by making stochastic decisions about whether to transmit that input or not (i.e. to determine the state of each hidden layer).  First, the probability vector is computed using the input feature vector $\\mathbf{x}$, the weight matrix $\\mathbf{W}$, and the bias term $h_{bias}$, as \n",
        "\n",
        "$p({h_j}|\\mathbf x)= \\sigma(\\sum_{i=1}^V W_{ij} x_i + h_{bias} )$, \n",
        "\n",
        "where $\\sigma(z) = (1+e^{-z})^{-1}$ is the logistic function.\n",
        "\n",
        "So, what does $p({h_j})$ represent? It is the <b>probability distribution</b> of the hidden units. That is, RBM uses inputs $x_i$ to make predictions about hidden node activations. For example, imagine that the hidden node activation values are [0.51 0.84] for the first training item. It tells you that the conditional probability for each hidden neuron for Phase 1 is: \n",
        "\n",
        "$$p(h_{1} = 1|\\mathbf{v}) = 0.51$$\n",
        "$$p(h_{2} = 1|\\mathbf{v}) = 0.84$$\n",
        "\n",
        "As a result, for each row in the training set, vector of probabilities is generated.  In TensorFlow, this is referred to as a `tensor` with a shape of (1,2). \n",
        "\n",
        "We then turn unit $j$ with probability $p(h_{j}|\\mathbf{v})$, and turn it off with probability $1 - p(h_{j}|\\mathbf{v})$ by generating a uniform random number vector $\\mathbf{\\xi}$, and comparing it to the activation probability as \n",
        "\n",
        "<center>If $\\xi_j>p(h_{j}|\\mathbf{v})$, then $h_j=1$, else $h_j=0$.</center>\n",
        "\n",
        "Therefore, the conditional probability of a configuration of $\\mathbf{h}$ given $\\mathbf{v}$ (for a training sample) is:\n",
        "\n",
        "$$p(\\mathbf{h} \\mid \\mathbf{v}) = \\prod_{j=1}^H p(h_j \\mid \\mathbf{v})$$\n",
        "\n",
        "where $H$ is the number of hidden units.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wfxxlyhR8OvB"
      },
      "source": [
        "Before we go further, let's look at a toy example for one case out of all input. Assume that we have a trained RBM, and a very simple input vector, such as [1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0].  \n",
        "Let's see what the output of forward pass would look like:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kPR3JeTS8OvC",
        "outputId": "5891fad6-944a-4ed3-dabc-dbc5df984641"
      },
      "source": [
        "X = tf.constant([[1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]], tf.float32)\n",
        "\n",
        "v_state = X\n",
        "print (\"Input: \", v_state)\n",
        "\n",
        "h_bias = tf.constant([0.1, 0.1])\n",
        "print (\"hb: \", h_bias)\n",
        "print (\"w: \", W)\n",
        "\n",
        "# Calculate the probabilities of turning the hidden units on:\n",
        "h_prob = tf.nn.sigmoid(tf.matmul(v_state, W) + h_bias)  #probabilities of the hidden units\n",
        "print (\"p(h|v): \", h_prob)\n",
        "\n",
        "# Draw samples from the distribution:\n",
        "h_state = tf.nn.relu(tf.sign(h_prob - tf.random.uniform(tf.shape(h_prob)))) #states\n",
        "print (\"h0 states:\", h_state)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input:  tf.Tensor([[1. 0. 0. 1. 0. 0. 0.]], shape=(1, 7), dtype=float32)\n",
            "hb:  tf.Tensor([0.1 0.1], shape=(2,), dtype=float32)\n",
            "w:  tf.Tensor(\n",
            "[[ 1.1509084  -0.6642517 ]\n",
            " [ 1.0219833  -0.16777591]\n",
            " [ 0.60805297 -1.8172042 ]\n",
            " [-0.5456829  -0.21189845]\n",
            " [ 0.01943833 -1.3955841 ]\n",
            " [-0.40676582 -0.48174858]\n",
            " [ 1.5027332   0.23451696]], shape=(7, 2), dtype=float32)\n",
            "p(h|v):  tf.Tensor([[0.6693453  0.31515023]], shape=(1, 2), dtype=float32)\n",
            "h0 states: tf.Tensor([[1. 0.]], shape=(1, 2), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZTHg7OIa8OvC"
      },
      "source": [
        "<b>Phase 2) Backward Pass (Reconstruction):</b>\n",
        "The RBM reconstructs data by making several forward and backward passes between the visible and hidden layers.\n",
        "\n",
        "So, in the second phase (i.e. reconstruction phase), the samples from the hidden layer (i.e. $\\mathbf h$) becomes the input in the backward pass. The same weight matrix and visible layer biases are used to passed to the sigmoid function. The reproduced output is a reconstruction which is an approximation of the original input.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "feqxpyl98OvC",
        "outputId": "a0b21a01-dd03-4efa-c201-7011a071a482"
      },
      "source": [
        "vb = tf.constant([0.1, 0.2, 0.1, 0.1, 0.1, 0.2, 0.1])\n",
        "print (\"b: \", vb)\n",
        "v_prob = tf.nn.sigmoid(tf.matmul(h_state, tf.transpose(W)) + vb)\n",
        "print (\"p(vi∣h): \", v_prob)\n",
        "v_state = tf.nn.relu(tf.sign(v_prob - tf.random.uniform(tf.shape(v_prob))))\n",
        "print (\"v probability states: \", v_state)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "b:  tf.Tensor([0.1 0.2 0.1 0.1 0.1 0.2 0.1], shape=(7,), dtype=float32)\n",
            "p(vi∣h):  tf.Tensor(\n",
            "[[0.77745706 0.7724124  0.6699708  0.39038765 0.52982414 0.4484919\n",
            "  0.8324    ]], shape=(1, 7), dtype=float32)\n",
            "v probability states:  tf.Tensor([[1. 1. 1. 0. 0. 0. 0.]], shape=(1, 7), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2OCpDs2V8OvD"
      },
      "source": [
        "RBM learns a probability distribution over the input, and then, after being trained, the RBM can generate new samples from the learned probability distribution. As you know, <b>probability distribution</b>, is a mathematical function that provides the probabilities of occurrence of different possible outcomes in an experiment.\n",
        "\n",
        "The (conditional) probability distribution over the visible units v is given by\n",
        "\n",
        "$p(\\mathbf{v} \\mid \\mathbf{h}) = \\prod_{i=1}^V p(v_i \\mid \\mathbf{h}),$\n",
        "\n",
        "where,\n",
        "\n",
        "$p(v_i \\mid \\mathbf{h}) = \\sigma\\left(\\sum_{j=1}^H W_{ji} h_j + v_{bias} \\right)$\n",
        "\n",
        "so, given current state of hidden units and weights, what is the probability of generating [1. 0. 0. 1. 0. 0. 0.] in reconstruction phase, based on the above <b>probability distribution</b> function?\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WojMYmaZ8OvD",
        "outputId": "560d7f03-d2f3-4522-e190-925c6ceb184b"
      },
      "source": [
        "inp = X\n",
        "print(\"input X:\" , inp.numpy())\n",
        "\n",
        "print(\"probablity vector:\" , v_prob[0].numpy())\n",
        "v_probability = 1\n",
        "\n",
        "for elm, p in zip(inp[0],v_prob[0]) :\n",
        "    if elm ==1:\n",
        "        v_probability *= p\n",
        "    else:\n",
        "        v_probability *= (1-p)\n",
        "\n",
        "print(\"probability of generating X: \" , v_probability.numpy())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "input X: [[1. 0. 0. 1. 0. 0. 0.]]\n",
            "probablity vector: [0.77745706 0.7724124  0.6699708  0.39038765 0.52982414 0.4484919\n",
            " 0.8324    ]\n",
            "probability of generating X:  0.0009907397\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6hPQ0KyF8OvD"
      },
      "source": [
        "How similar are vectors $\\mathbf{x}$ and $\\mathbf{v}$? Of course, the reconstructed values most likely will not look anything like the input vector, because our network has not been trained yet. Our objective is to train the model in such a way that the input vector and reconstructed vector to be same. Therefore, based on how different the input values look to the ones that we just reconstructed, the weights are adjusted. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TIljFy7k8OvD"
      },
      "source": [
        "<hr>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bepS5rVu8OvD"
      },
      "source": [
        "## **MNIST Dataset**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MH1vqkil8OvE"
      },
      "source": [
        "We will be using the MNIST dataset to practice the usage of RBMs. The following cell loads the MNIST dataset.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZEOyQpvN8OvE"
      },
      "source": [
        "#loading training and test data\n",
        "mnist = tf.keras.datasets.mnist\n",
        "(trX, trY), (teX, teY) = mnist.load_data()\n",
        "\n",
        "# showing an example of the Flatten class and operation\n",
        "from tensorflow.keras.layers import Flatten\n",
        "flatten = Flatten(dtype='float32')\n",
        "trX = flatten(trX/255.0)\n",
        "trY = flatten(trY/255.0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "97qoOAlU8OvE"
      },
      "source": [
        "Lets look at the dimension of the images.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kn6o_9328OvE"
      },
      "source": [
        "MNIST images have 784 pixels, so the visible layer must have 784 input nodes.  For our case, we'll use 50 nodes in the hidden layer, so i = 50.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SJe6cTOL8OvE"
      },
      "source": [
        "vb = tf.Variable(tf.zeros([784]), tf.float32)\n",
        "hb = tf.Variable(tf.zeros([50]), tf.float32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "waygAf698OvE"
      },
      "source": [
        "Let $\\mathbf W$ be the Tensor of 784x50 (784 -> number of visible neurons, 50 -> number of hidden neurons) that represents weights between the neurons. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UQM4KHzb8OvE"
      },
      "source": [
        "W = tf.Variable(tf.zeros([784,50]), tf.float32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eOtKiqml8OvE"
      },
      "source": [
        "Lets define the visible layer:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yJgb2JO18OvF",
        "outputId": "3a574549-9e09-4aba-bf4d-9626782d9cd1"
      },
      "source": [
        "v0_state = tf.Variable(tf.zeros([784]), tf.float32)\n",
        "\n",
        "#testing to see if the matrix product works\n",
        "tf.matmul( [v0_state], W)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 50), dtype=float32, numpy=\n",
              "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0.]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b0mDRDca8OvF"
      },
      "source": [
        "Now, we can define hidden layer:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4qxvwnMP8OvF",
        "outputId": "b840d439-7c01-48c2-9b03-aafaea317a49"
      },
      "source": [
        "#computing the hidden nodes probability vector and checking shape\n",
        "h0_prob = tf.nn.sigmoid(tf.matmul([v0_state], W) + hb)  #probabilities of the hidden units\n",
        "print(\"h0_state shape: \" , tf.shape(h0_prob))\n",
        "\n",
        "#defining a function to return only the generated hidden states \n",
        "def hidden_layer(v0_state, W, hb):\n",
        "    h0_prob = tf.nn.sigmoid(tf.matmul([v0_state], W) + hb)  #probabilities of the hidden units\n",
        "    h0_state = tf.nn.relu(tf.sign(h0_prob - tf.random.uniform(tf.shape(h0_prob)))) #sample_h_given_X\n",
        "    return h0_state\n",
        "\n",
        "\n",
        "h0_state = hidden_layer(v0_state, W, hb)\n",
        "print(\"first 15 hidden states: \", h0_state[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "h0_state shape:  tf.Tensor([ 1 50], shape=(2,), dtype=int32)\n",
            "first 15 hidden states:  tf.Tensor(\n",
            "[1. 0. 1. 0. 1. 0. 0. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 0.\n",
            " 0. 1. 1. 1. 0. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 0. 1. 1. 1. 0. 0.\n",
            " 1. 1.], shape=(50,), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "igq735n48OvF"
      },
      "source": [
        "Now, we define reconstruction part:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "63hghh5U8OvF",
        "outputId": "242680f3-5aab-47f5-cb22-899778e88d89"
      },
      "source": [
        "def reconstructed_output(h0_state, W, vb):\n",
        "    v1_prob = tf.nn.sigmoid(tf.matmul(h0_state, tf.transpose(W)) + vb) \n",
        "    v1_state = tf.nn.relu(tf.sign(v1_prob - tf.random.uniform(tf.shape(v1_prob)))) #sample_v_given_h\n",
        "    return v1_state[0]\n",
        "\n",
        "v1_state = reconstructed_output(h0_state, W, vb)\n",
        "print(\"hidden state shape: \", h0_state.shape)\n",
        "print(\"v0 state shape:  \", v0_state.shape)\n",
        "print(\"v1 state shape:  \", v1_state.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "hidden state shape:  (1, 50)\n",
            "v0 state shape:   (784,)\n",
            "v1 state shape:   (784,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mKbNnRRW8OvF"
      },
      "source": [
        "<h3>What is the objective function?</h3>\n",
        "\n",
        "<b>Goal</b>: Maximize the likelihood of our data being drawn from that distribution\n",
        "\n",
        "<b>Calculate error:</b>  \n",
        "In each epoch, we compute the \"error\" as a sum of the squared difference between step 1 and step n,\n",
        "e.g the error shows the difference between the data and its reconstruction.\n",
        "\n",
        "<b>Note:</b> tf.reduce_mean computes the mean of elements across dimensions of a tensor.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lvt_oFef8OvG",
        "outputId": "cd01bc4a-e4d1-4037-aeb5-23f081f73e5b"
      },
      "source": [
        "def error(v0_state, v1_state):\n",
        "    return tf.reduce_mean(tf.square(v0_state - v1_state))\n",
        "\n",
        "err = tf.reduce_mean(tf.square(v0_state - v1_state))\n",
        "print(\"error\" , err.numpy())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "error 0.4859694\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zp-oyA4o8OvG"
      },
      "source": [
        "<a id=\"ref4\"></a>\n",
        "\n",
        "<h3>Training the Model</h3>\n",
        "\n",
        "#### **Warning... The following part is math-heavy, but you can skip it if you just want to run the cells in the next section.**\n",
        "\n",
        "As mentioned, we want to give a high probability to the input data we train on. So, in order to train an RBM, we have to maximize the product of probabilities assigned to all rows $\\mathbf{v}$ (images) in the training set $\\mathbf{V}$ (a matrix, where each row of it is treated as a visible vector $\\mathbf{v}$)\n",
        "\n",
        "$$\\arg\\max_W\\prod_{\\mathbf{v}\\in\\mathbf{V}_T}p(\\mathbf{v}),$$\n",
        "\n",
        "which is equivalent to maximizing the expectation of the log probability, given as\n",
        "\n",
        "$$\\arg\\max_W\\left[ \\mathbb{E} \\left(\\prod_{\\mathbf v\\in \\mathbf V}\\text{log} \\left(p(\\mathbf v)\\right) \\right) \\right].$$\n",
        "\n",
        "So, we have to update the weights $W_{ij}$  to increase $p(\\mathbf{v})$ for all $\\mathbf{v}$ in our training data during training. So we have to calculate the derivative:\n",
        "\n",
        "$$\\frac{\\partial \\log p(\\mathbf v)}{\\partial W_{ij}}$$\n",
        "\n",
        "This cannot be easily done by typical <b>gradient descent (SGD)</b>, so we can use another approach, which has 2 steps:\n",
        "\n",
        "<ol>\n",
        "    <li>Gibbs Sampling</li>\n",
        "    <li>Contrastive Divergence</li>\n",
        "</ol>    \n",
        "    \n",
        "<h3>Gibbs Sampling</h3>   \n",
        "\n",
        "<h4>Gibbs Sampling Step 1</h4> \n",
        "Given an input vector $\\mathbf{v}$, we are using $p(\\mathbf{h}|\\mathbf{v})$ to predict the hidden values $\\mathbf{h}$. \n",
        "  $$p({h_j}|\\mathbf v)= \\sigma\\left(\\sum_{i=1}^V W_{ij} v_i + h_{bias} \\right)$$\n",
        "The samples are generated from this distribution by generating the uniform random variate vector $\\mathbf{\\xi} \\sim U[0,1]$ of length $H$ and comparing to the computed probabilities as\n",
        "\n",
        "<center>If $\\xi_j>p(h_{j}|\\mathbf{v})$, then $h_j=1$, else $h_j=0$.</center>\n",
        "\n",
        "<h4>Gibbs Sampling Step 2</h4> \n",
        "Then, knowing the hidden values, we use $p(\\mathbf v| \\mathbf h)$ for reconstructing of new input values v. \n",
        "\n",
        "   $$p({v_i}|\\mathbf h)= \\sigma\\left(\\sum_{j=1}^H W^{T}_{ij} h_j + v_{bias} \\right)$$\n",
        "\n",
        "The samples are generated from this distribution by generating a uniform random variate vector $\\mathbf{\\xi} \\sim U[0,1]$ of length $V$ and comparing to the computed probabilities as\n",
        "\n",
        "<center>If $\\xi_i>p(v_{i}|\\mathbf{h})$, then $v_i=1$, else $v_i=0$.</center>\n",
        "\n",
        "Let vectors $\\mathbf v_k$ and $\\mathbf h_k$ be for the $k$th iteration.  In general, the $kth$ state is generrated as: \n",
        "\n",
        "<b>Iteration</b> $k$: \n",
        "\n",
        "$$\\mathbf v_{k-1} \\Rightarrow p(\\mathbf h_{k-1}|\\mathbf v_{k-1})\\Rightarrow \\mathbf h_{k-1}\\Rightarrow p(\\mathbf v_{k}|\\mathbf h_{k-1})\\Rightarrow \\mathbf v_k$$       \n",
        "\n",
        "<h3>Contrastive Divergence (CD-k)</h3>\n",
        "The update of the weight matrix is done during the Contrastive Divergence step. \n",
        "\n",
        "Vectors v0 and vk are used to calculate the activation probabilities for hidden values h0 and hk. The difference between the outer products of those probabilities with input vectors v0 and vk results in the update matrix:\n",
        "\n",
        "$\\Delta \\mathbf W_k =\\mathbf v_k \\otimes \\mathbf h_k - \\mathbf v_{k-1} \\otimes \\mathbf h_{k-1}$ \n",
        "\n",
        "Contrastive Divergence is actually matrix of values that is computed and used to adjust values of the $\\mathbf W$ matrix. Changing $\\mathbf W$ incrementally leads to training of the  $\\mathbf W$ values. Then, on each step (epoch), $\\mathbf W$ is updated using the following:\n",
        "\n",
        "$\\mathbf W_k = \\mathbf W_{k-1} + \\alpha * \\Delta \\mathbf W_k$ \n",
        "\n",
        "Reconstruction steps:\n",
        "\n",
        "<ul>\n",
        "    <li> Get one data point from data set, like <i>x</i>, and pass it through the following steps:</li>\n",
        "    \n",
        "<b>Iteration</b> $k=1$: \n",
        "    \n",
        "Sampling (starting with input image)\n",
        "    $$\\mathbf x = \\mathbf v_0 \\Rightarrow p(\\mathbf h_0|\\mathbf v_0)\\Rightarrow \\mathbf h_0 \\Rightarrow p(\\mathbf v_1|\\mathbf h_0)\\Rightarrow \\mathbf v_1$$   \n",
        "    followed by the CD-k step\n",
        "$$\\Delta \\mathbf W_1 =\\mathbf v_1 \\otimes \\mathbf h_1 - \\mathbf v_{0} \\otimes \\mathbf h_{0}$$     \n",
        "$$\\mathbf W_1 = \\mathbf W_{0} + \\alpha * \\Delta \\mathbf W_1$$ \n",
        " \n",
        "<li> $\\mathbf v_1$ is the reconstruction of $\\mathbf x$ sent to the next iteration).</li>\n",
        "\n",
        "<b>Iteration</b> $k=2$: \n",
        "\n",
        "Sampling (starting with $\\mathbf v_1$)\n",
        "\n",
        "$$\\mathbf v_1 \\Rightarrow p(\\mathbf h_1|\\mathbf v_1)\\Rightarrow \\mathbf h_1\\Rightarrow p(\\mathbf v_2|\\mathbf h_1)\\Rightarrow \\mathbf v_2$$   \n",
        "\n",
        "followed by the CD-k step\n",
        "$$\\Delta \\mathbf W_2 =\\mathbf v_2 \\otimes \\mathbf h_2 - \\mathbf v_{1} \\otimes \\mathbf h_{1}$$  \n",
        "$$\\mathbf W_2 = \\mathbf W_{1} + \\alpha * \\Delta \\mathbf W_2$$ \n",
        "\n",
        "<li> $\\mathbf v_2$ is the reconstruction of $\\mathbf v_1$ sent to the next iteration).</li>    \n",
        "      \n",
        "<b>Iteration</b> $k=K$:\n",
        "    \n",
        "Sampling (starting with $\\mathbf v_{K-1}$)\n",
        "\n",
        "$$\\mathbf v_{K-1} \\Rightarrow p(\\mathbf h_{K-1}|\\mathbf v_{K-1})\\Rightarrow \\mathbf h_{K-1}\\Rightarrow p(\\mathbf v_K|\\mathbf h_{K-1})\\Rightarrow \\mathbf v_K$$   \n",
        "\n",
        "followed by the CD-k step\n",
        "$$\\Delta \\mathbf W_K =\\mathbf v_K \\otimes \\mathbf h_K - \\mathbf v_{K-1} \\otimes \\mathbf h_{K-1}$$  \n",
        "$$\\mathbf W_K = \\mathbf W_{K-1} + \\alpha * \\Delta \\mathbf W_K$$ \n",
        "\n",
        "<b>What is $\\alpha$?</b>  \n",
        "Here, alpha is some small step size, and is also known as the \"learning rate\".\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZbgnZ5lT8OvH"
      },
      "source": [
        "$K$ is adjustable, and good performance can be achieved with $K=1$, so that we just take one set of sampling steps per image.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2i0Z0CZ38OvI"
      },
      "source": [
        "h1_prob = tf.nn.sigmoid(tf.matmul([v1_state], W) + hb)\n",
        "h1_state = tf.nn.relu(tf.sign(h1_prob - tf.random.uniform(tf.shape(h1_prob)))) #sample_h_given_X"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hrf41GSE8OvI"
      },
      "source": [
        "Lets look at the error of the first run:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nzRPbBvk8OvJ",
        "outputId": "f0996e1d-dc8f-4d03-9eb6-9d28faee90a8"
      },
      "source": [
        "print(\"error: \", error(v0_state, v1_state))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "error:  tf.Tensor(0.4859694, shape=(), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FR5Ve1Nc8OvJ",
        "outputId": "15fbdcb5-bdef-4df1-f371-69d0c6d4e171"
      },
      "source": [
        "#Parameters\n",
        "alpha = 0.001\n",
        "epochs = 2\n",
        "batchsize = 200\n",
        "weights = []\n",
        "errors = []\n",
        "batch_number = 0\n",
        "K = 1\n",
        "\n",
        "#creating datasets\n",
        "train_ds = \\\n",
        "    tf.data.Dataset.from_tensor_slices((trX, trY)).batch(batchsize)\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    for batch_x, batch_y in train_ds:\n",
        "        batch_number += 1\n",
        "        for i_sample in range(batchsize):           \n",
        "            for k in range(K):\n",
        "                v0_state = batch_x[i_sample]\n",
        "                h0_state = hidden_layer(v0_state, W, hb)\n",
        "                v1_state = reconstructed_output(h0_state, W, vb)\n",
        "                h1_state = hidden_layer(v1_state, W, hb)\n",
        "\n",
        "                delta_W = tf.matmul(tf.transpose([v0_state]), h0_state) - tf.matmul(tf.transpose([v1_state]), h1_state)\n",
        "                W = W + alpha * delta_W\n",
        "\n",
        "                vb = vb + alpha * tf.reduce_mean(v0_state - v1_state, 0)\n",
        "                hb = hb + alpha * tf.reduce_mean(h0_state - h1_state, 0) \n",
        "\n",
        "                v0_state = v1_state\n",
        "\n",
        "            if i_sample == batchsize-1:\n",
        "                err = error(batch_x[i_sample], v1_state)\n",
        "                errors.append(err)\n",
        "                weights.append(W)\n",
        "                print ( 'Epoch: %d' % epoch, \n",
        "                       \"batch #: %i \" % batch_number, \"of %i\" % int(60e3/batchsize), \n",
        "                       \"sample #: %i\" % i_sample,\n",
        "                       'reconstruction error: %f' % err)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0 batch #: 1  of 300 sample #: 199 reconstruction error: 0.101013\n",
            "Epoch: 0 batch #: 2  of 300 sample #: 199 reconstruction error: 0.094085\n",
            "Epoch: 0 batch #: 3  of 300 sample #: 199 reconstruction error: 0.059020\n",
            "Epoch: 0 batch #: 4  of 300 sample #: 199 reconstruction error: 0.062031\n",
            "Epoch: 0 batch #: 5  of 300 sample #: 199 reconstruction error: 0.064394\n",
            "Epoch: 0 batch #: 6  of 300 sample #: 199 reconstruction error: 0.126600\n",
            "Epoch: 0 batch #: 7  of 300 sample #: 199 reconstruction error: 0.061928\n",
            "Epoch: 0 batch #: 8  of 300 sample #: 199 reconstruction error: 0.063656\n",
            "Epoch: 0 batch #: 9  of 300 sample #: 199 reconstruction error: 0.066054\n",
            "Epoch: 0 batch #: 10  of 300 sample #: 199 reconstruction error: 0.121384\n",
            "Epoch: 0 batch #: 11  of 300 sample #: 199 reconstruction error: 0.056562\n",
            "Epoch: 0 batch #: 12  of 300 sample #: 199 reconstruction error: 0.102282\n",
            "Epoch: 0 batch #: 13  of 300 sample #: 199 reconstruction error: 0.024498\n",
            "Epoch: 0 batch #: 14  of 300 sample #: 199 reconstruction error: 0.050827\n",
            "Epoch: 0 batch #: 15  of 300 sample #: 199 reconstruction error: 0.073265\n",
            "Epoch: 0 batch #: 16  of 300 sample #: 199 reconstruction error: 0.080151\n",
            "Epoch: 0 batch #: 17  of 300 sample #: 199 reconstruction error: 0.045396\n",
            "Epoch: 0 batch #: 18  of 300 sample #: 199 reconstruction error: 0.085556\n",
            "Epoch: 0 batch #: 19  of 300 sample #: 199 reconstruction error: 0.115906\n",
            "Epoch: 0 batch #: 20  of 300 sample #: 199 reconstruction error: 0.087325\n",
            "Epoch: 0 batch #: 21  of 300 sample #: 199 reconstruction error: 0.064648\n",
            "Epoch: 0 batch #: 22  of 300 sample #: 199 reconstruction error: 0.056560\n",
            "Epoch: 0 batch #: 23  of 300 sample #: 199 reconstruction error: 0.090392\n",
            "Epoch: 0 batch #: 24  of 300 sample #: 199 reconstruction error: 0.101465\n",
            "Epoch: 0 batch #: 25  of 300 sample #: 199 reconstruction error: 0.084784\n",
            "Epoch: 0 batch #: 26  of 300 sample #: 199 reconstruction error: 0.079249\n",
            "Epoch: 0 batch #: 27  of 300 sample #: 199 reconstruction error: 0.100220\n",
            "Epoch: 0 batch #: 28  of 300 sample #: 199 reconstruction error: 0.053858\n",
            "Epoch: 0 batch #: 29  of 300 sample #: 199 reconstruction error: 0.091642\n",
            "Epoch: 0 batch #: 30  of 300 sample #: 199 reconstruction error: 0.068880\n",
            "Epoch: 0 batch #: 31  of 300 sample #: 199 reconstruction error: 0.056054\n",
            "Epoch: 0 batch #: 32  of 300 sample #: 199 reconstruction error: 0.097595\n",
            "Epoch: 0 batch #: 33  of 300 sample #: 199 reconstruction error: 0.052535\n",
            "Epoch: 0 batch #: 34  of 300 sample #: 199 reconstruction error: 0.061980\n",
            "Epoch: 0 batch #: 35  of 300 sample #: 199 reconstruction error: 0.064591\n",
            "Epoch: 0 batch #: 36  of 300 sample #: 199 reconstruction error: 0.093557\n",
            "Epoch: 0 batch #: 37  of 300 sample #: 199 reconstruction error: 0.042820\n",
            "Epoch: 0 batch #: 38  of 300 sample #: 199 reconstruction error: 0.052526\n",
            "Epoch: 0 batch #: 39  of 300 sample #: 199 reconstruction error: 0.083623\n",
            "Epoch: 0 batch #: 40  of 300 sample #: 199 reconstruction error: 0.084008\n",
            "Epoch: 0 batch #: 41  of 300 sample #: 199 reconstruction error: 0.063232\n",
            "Epoch: 0 batch #: 42  of 300 sample #: 199 reconstruction error: 0.053315\n",
            "Epoch: 0 batch #: 43  of 300 sample #: 199 reconstruction error: 0.112498\n",
            "Epoch: 0 batch #: 44  of 300 sample #: 199 reconstruction error: 0.059510\n",
            "Epoch: 0 batch #: 45  of 300 sample #: 199 reconstruction error: 0.054665\n",
            "Epoch: 0 batch #: 46  of 300 sample #: 199 reconstruction error: 0.032887\n",
            "Epoch: 0 batch #: 47  of 300 sample #: 199 reconstruction error: 0.039440\n",
            "Epoch: 0 batch #: 48  of 300 sample #: 199 reconstruction error: 0.030923\n",
            "Epoch: 0 batch #: 49  of 300 sample #: 199 reconstruction error: 0.109487\n",
            "Epoch: 0 batch #: 50  of 300 sample #: 199 reconstruction error: 0.048067\n",
            "Epoch: 0 batch #: 51  of 300 sample #: 199 reconstruction error: 0.053857\n",
            "Epoch: 0 batch #: 52  of 300 sample #: 199 reconstruction error: 0.027352\n",
            "Epoch: 0 batch #: 53  of 300 sample #: 199 reconstruction error: 0.065486\n",
            "Epoch: 0 batch #: 54  of 300 sample #: 199 reconstruction error: 0.033867\n",
            "Epoch: 0 batch #: 55  of 300 sample #: 199 reconstruction error: 0.086015\n",
            "Epoch: 0 batch #: 56  of 300 sample #: 199 reconstruction error: 0.045501\n",
            "Epoch: 0 batch #: 57  of 300 sample #: 199 reconstruction error: 0.045443\n",
            "Epoch: 0 batch #: 58  of 300 sample #: 199 reconstruction error: 0.066184\n",
            "Epoch: 0 batch #: 59  of 300 sample #: 199 reconstruction error: 0.061098\n",
            "Epoch: 0 batch #: 60  of 300 sample #: 199 reconstruction error: 0.096025\n",
            "Epoch: 0 batch #: 61  of 300 sample #: 199 reconstruction error: 0.068512\n",
            "Epoch: 0 batch #: 62  of 300 sample #: 199 reconstruction error: 0.066808\n",
            "Epoch: 0 batch #: 63  of 300 sample #: 199 reconstruction error: 0.038204\n",
            "Epoch: 0 batch #: 64  of 300 sample #: 199 reconstruction error: 0.072677\n",
            "Epoch: 0 batch #: 65  of 300 sample #: 199 reconstruction error: 0.098255\n",
            "Epoch: 0 batch #: 66  of 300 sample #: 199 reconstruction error: 0.051687\n",
            "Epoch: 0 batch #: 67  of 300 sample #: 199 reconstruction error: 0.044903\n",
            "Epoch: 0 batch #: 68  of 300 sample #: 199 reconstruction error: 0.062243\n",
            "Epoch: 0 batch #: 69  of 300 sample #: 199 reconstruction error: 0.064140\n",
            "Epoch: 0 batch #: 70  of 300 sample #: 199 reconstruction error: 0.087260\n",
            "Epoch: 0 batch #: 71  of 300 sample #: 199 reconstruction error: 0.072649\n",
            "Epoch: 0 batch #: 72  of 300 sample #: 199 reconstruction error: 0.061605\n",
            "Epoch: 0 batch #: 73  of 300 sample #: 199 reconstruction error: 0.077900\n",
            "Epoch: 0 batch #: 74  of 300 sample #: 199 reconstruction error: 0.065092\n",
            "Epoch: 0 batch #: 75  of 300 sample #: 199 reconstruction error: 0.052875\n",
            "Epoch: 0 batch #: 76  of 300 sample #: 199 reconstruction error: 0.062395\n",
            "Epoch: 0 batch #: 77  of 300 sample #: 199 reconstruction error: 0.098743\n",
            "Epoch: 0 batch #: 78  of 300 sample #: 199 reconstruction error: 0.086112\n",
            "Epoch: 0 batch #: 79  of 300 sample #: 199 reconstruction error: 0.095011\n",
            "Epoch: 0 batch #: 80  of 300 sample #: 199 reconstruction error: 0.031561\n",
            "Epoch: 0 batch #: 81  of 300 sample #: 199 reconstruction error: 0.048008\n",
            "Epoch: 0 batch #: 82  of 300 sample #: 199 reconstruction error: 0.042196\n",
            "Epoch: 0 batch #: 83  of 300 sample #: 199 reconstruction error: 0.080737\n",
            "Epoch: 0 batch #: 84  of 300 sample #: 199 reconstruction error: 0.083345\n",
            "Epoch: 0 batch #: 85  of 300 sample #: 199 reconstruction error: 0.054747\n",
            "Epoch: 0 batch #: 86  of 300 sample #: 199 reconstruction error: 0.071323\n",
            "Epoch: 0 batch #: 87  of 300 sample #: 199 reconstruction error: 0.073810\n",
            "Epoch: 0 batch #: 88  of 300 sample #: 199 reconstruction error: 0.027246\n",
            "Epoch: 0 batch #: 89  of 300 sample #: 199 reconstruction error: 0.050520\n",
            "Epoch: 0 batch #: 90  of 300 sample #: 199 reconstruction error: 0.065671\n",
            "Epoch: 0 batch #: 91  of 300 sample #: 199 reconstruction error: 0.051112\n",
            "Epoch: 0 batch #: 92  of 300 sample #: 199 reconstruction error: 0.059101\n",
            "Epoch: 0 batch #: 93  of 300 sample #: 199 reconstruction error: 0.102327\n",
            "Epoch: 0 batch #: 94  of 300 sample #: 199 reconstruction error: 0.101580\n",
            "Epoch: 0 batch #: 95  of 300 sample #: 199 reconstruction error: 0.047963\n",
            "Epoch: 0 batch #: 96  of 300 sample #: 199 reconstruction error: 0.049619\n",
            "Epoch: 0 batch #: 97  of 300 sample #: 199 reconstruction error: 0.098342\n",
            "Epoch: 0 batch #: 98  of 300 sample #: 199 reconstruction error: 0.073783\n",
            "Epoch: 0 batch #: 99  of 300 sample #: 199 reconstruction error: 0.045631\n",
            "Epoch: 0 batch #: 100  of 300 sample #: 199 reconstruction error: 0.093922\n",
            "Epoch: 0 batch #: 101  of 300 sample #: 199 reconstruction error: 0.075528\n",
            "Epoch: 0 batch #: 102  of 300 sample #: 199 reconstruction error: 0.103936\n",
            "Epoch: 0 batch #: 103  of 300 sample #: 199 reconstruction error: 0.063979\n",
            "Epoch: 0 batch #: 104  of 300 sample #: 199 reconstruction error: 0.056127\n",
            "Epoch: 0 batch #: 105  of 300 sample #: 199 reconstruction error: 0.051227\n",
            "Epoch: 0 batch #: 106  of 300 sample #: 199 reconstruction error: 0.099259\n",
            "Epoch: 0 batch #: 107  of 300 sample #: 199 reconstruction error: 0.125218\n",
            "Epoch: 0 batch #: 108  of 300 sample #: 199 reconstruction error: 0.054946\n",
            "Epoch: 0 batch #: 109  of 300 sample #: 199 reconstruction error: 0.113376\n",
            "Epoch: 0 batch #: 110  of 300 sample #: 199 reconstruction error: 0.059097\n",
            "Epoch: 0 batch #: 111  of 300 sample #: 199 reconstruction error: 0.098091\n",
            "Epoch: 0 batch #: 112  of 300 sample #: 199 reconstruction error: 0.035098\n",
            "Epoch: 0 batch #: 113  of 300 sample #: 199 reconstruction error: 0.063665\n",
            "Epoch: 0 batch #: 114  of 300 sample #: 199 reconstruction error: 0.078526\n",
            "Epoch: 0 batch #: 115  of 300 sample #: 199 reconstruction error: 0.053723\n",
            "Epoch: 0 batch #: 116  of 300 sample #: 199 reconstruction error: 0.045543\n",
            "Epoch: 0 batch #: 117  of 300 sample #: 199 reconstruction error: 0.048075\n",
            "Epoch: 0 batch #: 118  of 300 sample #: 199 reconstruction error: 0.070894\n",
            "Epoch: 0 batch #: 119  of 300 sample #: 199 reconstruction error: 0.113879\n",
            "Epoch: 0 batch #: 120  of 300 sample #: 199 reconstruction error: 0.059699\n",
            "Epoch: 0 batch #: 121  of 300 sample #: 199 reconstruction error: 0.035930\n",
            "Epoch: 0 batch #: 122  of 300 sample #: 199 reconstruction error: 0.086552\n",
            "Epoch: 0 batch #: 123  of 300 sample #: 199 reconstruction error: 0.061202\n",
            "Epoch: 0 batch #: 124  of 300 sample #: 199 reconstruction error: 0.084798\n",
            "Epoch: 0 batch #: 125  of 300 sample #: 199 reconstruction error: 0.052984\n",
            "Epoch: 0 batch #: 126  of 300 sample #: 199 reconstruction error: 0.099013\n",
            "Epoch: 0 batch #: 127  of 300 sample #: 199 reconstruction error: 0.092636\n",
            "Epoch: 0 batch #: 128  of 300 sample #: 199 reconstruction error: 0.073229\n",
            "Epoch: 0 batch #: 129  of 300 sample #: 199 reconstruction error: 0.058848\n",
            "Epoch: 0 batch #: 130  of 300 sample #: 199 reconstruction error: 0.075039\n",
            "Epoch: 0 batch #: 131  of 300 sample #: 199 reconstruction error: 0.055524\n",
            "Epoch: 0 batch #: 132  of 300 sample #: 199 reconstruction error: 0.036192\n",
            "Epoch: 0 batch #: 133  of 300 sample #: 199 reconstruction error: 0.059466\n",
            "Epoch: 0 batch #: 134  of 300 sample #: 199 reconstruction error: 0.100824\n",
            "Epoch: 0 batch #: 135  of 300 sample #: 199 reconstruction error: 0.072435\n",
            "Epoch: 0 batch #: 136  of 300 sample #: 199 reconstruction error: 0.090340\n",
            "Epoch: 0 batch #: 137  of 300 sample #: 199 reconstruction error: 0.069901\n",
            "Epoch: 0 batch #: 138  of 300 sample #: 199 reconstruction error: 0.086283\n",
            "Epoch: 0 batch #: 139  of 300 sample #: 199 reconstruction error: 0.104673\n",
            "Epoch: 0 batch #: 140  of 300 sample #: 199 reconstruction error: 0.080753\n",
            "Epoch: 0 batch #: 141  of 300 sample #: 199 reconstruction error: 0.076438\n",
            "Epoch: 0 batch #: 142  of 300 sample #: 199 reconstruction error: 0.054538\n",
            "Epoch: 0 batch #: 143  of 300 sample #: 199 reconstruction error: 0.052545\n",
            "Epoch: 0 batch #: 144  of 300 sample #: 199 reconstruction error: 0.071379\n",
            "Epoch: 0 batch #: 145  of 300 sample #: 199 reconstruction error: 0.101245\n",
            "Epoch: 0 batch #: 146  of 300 sample #: 199 reconstruction error: 0.106791\n",
            "Epoch: 0 batch #: 147  of 300 sample #: 199 reconstruction error: 0.084106\n",
            "Epoch: 0 batch #: 148  of 300 sample #: 199 reconstruction error: 0.070943\n",
            "Epoch: 0 batch #: 149  of 300 sample #: 199 reconstruction error: 0.061049\n",
            "Epoch: 0 batch #: 150  of 300 sample #: 199 reconstruction error: 0.026298\n",
            "Epoch: 0 batch #: 151  of 300 sample #: 199 reconstruction error: 0.116320\n",
            "Epoch: 0 batch #: 152  of 300 sample #: 199 reconstruction error: 0.075181\n",
            "Epoch: 0 batch #: 153  of 300 sample #: 199 reconstruction error: 0.058842\n",
            "Epoch: 0 batch #: 154  of 300 sample #: 199 reconstruction error: 0.063788\n",
            "Epoch: 0 batch #: 155  of 300 sample #: 199 reconstruction error: 0.067710\n",
            "Epoch: 0 batch #: 156  of 300 sample #: 199 reconstruction error: 0.079914\n",
            "Epoch: 0 batch #: 157  of 300 sample #: 199 reconstruction error: 0.079428\n",
            "Epoch: 0 batch #: 158  of 300 sample #: 199 reconstruction error: 0.064412\n",
            "Epoch: 0 batch #: 159  of 300 sample #: 199 reconstruction error: 0.060862\n",
            "Epoch: 0 batch #: 160  of 300 sample #: 199 reconstruction error: 0.080987\n",
            "Epoch: 0 batch #: 161  of 300 sample #: 199 reconstruction error: 0.081810\n",
            "Epoch: 0 batch #: 162  of 300 sample #: 199 reconstruction error: 0.119491\n",
            "Epoch: 0 batch #: 163  of 300 sample #: 199 reconstruction error: 0.042358\n",
            "Epoch: 0 batch #: 164  of 300 sample #: 199 reconstruction error: 0.054586\n",
            "Epoch: 0 batch #: 165  of 300 sample #: 199 reconstruction error: 0.085642\n",
            "Epoch: 0 batch #: 166  of 300 sample #: 199 reconstruction error: 0.054513\n",
            "Epoch: 0 batch #: 167  of 300 sample #: 199 reconstruction error: 0.090201\n",
            "Epoch: 0 batch #: 168  of 300 sample #: 199 reconstruction error: 0.053328\n",
            "Epoch: 0 batch #: 169  of 300 sample #: 199 reconstruction error: 0.028763\n",
            "Epoch: 0 batch #: 170  of 300 sample #: 199 reconstruction error: 0.053556\n",
            "Epoch: 0 batch #: 171  of 300 sample #: 199 reconstruction error: 0.032191\n",
            "Epoch: 0 batch #: 172  of 300 sample #: 199 reconstruction error: 0.039542\n",
            "Epoch: 0 batch #: 173  of 300 sample #: 199 reconstruction error: 0.086119\n",
            "Epoch: 0 batch #: 174  of 300 sample #: 199 reconstruction error: 0.095988\n",
            "Epoch: 0 batch #: 175  of 300 sample #: 199 reconstruction error: 0.061669\n",
            "Epoch: 0 batch #: 176  of 300 sample #: 199 reconstruction error: 0.039994\n",
            "Epoch: 0 batch #: 177  of 300 sample #: 199 reconstruction error: 0.040939\n",
            "Epoch: 0 batch #: 178  of 300 sample #: 199 reconstruction error: 0.113753\n",
            "Epoch: 0 batch #: 179  of 300 sample #: 199 reconstruction error: 0.067366\n",
            "Epoch: 0 batch #: 180  of 300 sample #: 199 reconstruction error: 0.087003\n",
            "Epoch: 0 batch #: 181  of 300 sample #: 199 reconstruction error: 0.095277\n",
            "Epoch: 0 batch #: 182  of 300 sample #: 199 reconstruction error: 0.078537\n",
            "Epoch: 0 batch #: 183  of 300 sample #: 199 reconstruction error: 0.106918\n",
            "Epoch: 0 batch #: 184  of 300 sample #: 199 reconstruction error: 0.064603\n",
            "Epoch: 0 batch #: 185  of 300 sample #: 199 reconstruction error: 0.094417\n",
            "Epoch: 0 batch #: 186  of 300 sample #: 199 reconstruction error: 0.109972\n",
            "Epoch: 0 batch #: 187  of 300 sample #: 199 reconstruction error: 0.052061\n",
            "Epoch: 0 batch #: 188  of 300 sample #: 199 reconstruction error: 0.092738\n",
            "Epoch: 0 batch #: 189  of 300 sample #: 199 reconstruction error: 0.075741\n",
            "Epoch: 0 batch #: 190  of 300 sample #: 199 reconstruction error: 0.050718\n",
            "Epoch: 0 batch #: 191  of 300 sample #: 199 reconstruction error: 0.126846\n",
            "Epoch: 0 batch #: 192  of 300 sample #: 199 reconstruction error: 0.124011\n",
            "Epoch: 0 batch #: 193  of 300 sample #: 199 reconstruction error: 0.102073\n",
            "Epoch: 0 batch #: 194  of 300 sample #: 199 reconstruction error: 0.075357\n",
            "Epoch: 0 batch #: 195  of 300 sample #: 199 reconstruction error: 0.051771\n",
            "Epoch: 0 batch #: 196  of 300 sample #: 199 reconstruction error: 0.049749\n",
            "Epoch: 0 batch #: 197  of 300 sample #: 199 reconstruction error: 0.054885\n",
            "Epoch: 0 batch #: 198  of 300 sample #: 199 reconstruction error: 0.087423\n",
            "Epoch: 0 batch #: 199  of 300 sample #: 199 reconstruction error: 0.079169\n",
            "Epoch: 0 batch #: 200  of 300 sample #: 199 reconstruction error: 0.086750\n",
            "Epoch: 0 batch #: 201  of 300 sample #: 199 reconstruction error: 0.069664\n",
            "Epoch: 0 batch #: 202  of 300 sample #: 199 reconstruction error: 0.024832\n",
            "Epoch: 0 batch #: 203  of 300 sample #: 199 reconstruction error: 0.082738\n",
            "Epoch: 0 batch #: 204  of 300 sample #: 199 reconstruction error: 0.051490\n",
            "Epoch: 0 batch #: 205  of 300 sample #: 199 reconstruction error: 0.029149\n",
            "Epoch: 0 batch #: 206  of 300 sample #: 199 reconstruction error: 0.048451\n",
            "Epoch: 0 batch #: 207  of 300 sample #: 199 reconstruction error: 0.080457\n",
            "Epoch: 0 batch #: 208  of 300 sample #: 199 reconstruction error: 0.048098\n",
            "Epoch: 0 batch #: 209  of 300 sample #: 199 reconstruction error: 0.028400\n",
            "Epoch: 0 batch #: 210  of 300 sample #: 199 reconstruction error: 0.111062\n",
            "Epoch: 0 batch #: 211  of 300 sample #: 199 reconstruction error: 0.082195\n",
            "Epoch: 0 batch #: 212  of 300 sample #: 199 reconstruction error: 0.091240\n",
            "Epoch: 0 batch #: 213  of 300 sample #: 199 reconstruction error: 0.100518\n",
            "Epoch: 0 batch #: 214  of 300 sample #: 199 reconstruction error: 0.093990\n",
            "Epoch: 0 batch #: 215  of 300 sample #: 199 reconstruction error: 0.027036\n",
            "Epoch: 0 batch #: 216  of 300 sample #: 199 reconstruction error: 0.098841\n",
            "Epoch: 0 batch #: 217  of 300 sample #: 199 reconstruction error: 0.086143\n",
            "Epoch: 0 batch #: 218  of 300 sample #: 199 reconstruction error: 0.060058\n",
            "Epoch: 0 batch #: 219  of 300 sample #: 199 reconstruction error: 0.065579\n",
            "Epoch: 0 batch #: 220  of 300 sample #: 199 reconstruction error: 0.070410\n",
            "Epoch: 0 batch #: 221  of 300 sample #: 199 reconstruction error: 0.106040\n",
            "Epoch: 0 batch #: 222  of 300 sample #: 199 reconstruction error: 0.061926\n",
            "Epoch: 0 batch #: 223  of 300 sample #: 199 reconstruction error: 0.068556\n",
            "Epoch: 0 batch #: 224  of 300 sample #: 199 reconstruction error: 0.069293\n",
            "Epoch: 0 batch #: 225  of 300 sample #: 199 reconstruction error: 0.070748\n",
            "Epoch: 0 batch #: 226  of 300 sample #: 199 reconstruction error: 0.137866\n",
            "Epoch: 0 batch #: 227  of 300 sample #: 199 reconstruction error: 0.075585\n",
            "Epoch: 0 batch #: 228  of 300 sample #: 199 reconstruction error: 0.065680\n",
            "Epoch: 0 batch #: 229  of 300 sample #: 199 reconstruction error: 0.083878\n",
            "Epoch: 0 batch #: 230  of 300 sample #: 199 reconstruction error: 0.035594\n",
            "Epoch: 0 batch #: 231  of 300 sample #: 199 reconstruction error: 0.023899\n",
            "Epoch: 0 batch #: 232  of 300 sample #: 199 reconstruction error: 0.073255\n",
            "Epoch: 0 batch #: 233  of 300 sample #: 199 reconstruction error: 0.079484\n",
            "Epoch: 0 batch #: 234  of 300 sample #: 199 reconstruction error: 0.070959\n",
            "Epoch: 0 batch #: 235  of 300 sample #: 199 reconstruction error: 0.070255\n",
            "Epoch: 0 batch #: 236  of 300 sample #: 199 reconstruction error: 0.093079\n",
            "Epoch: 0 batch #: 237  of 300 sample #: 199 reconstruction error: 0.081321\n",
            "Epoch: 0 batch #: 238  of 300 sample #: 199 reconstruction error: 0.120903\n",
            "Epoch: 0 batch #: 239  of 300 sample #: 199 reconstruction error: 0.032692\n",
            "Epoch: 0 batch #: 240  of 300 sample #: 199 reconstruction error: 0.100482\n",
            "Epoch: 0 batch #: 241  of 300 sample #: 199 reconstruction error: 0.094800\n",
            "Epoch: 0 batch #: 242  of 300 sample #: 199 reconstruction error: 0.055544\n",
            "Epoch: 0 batch #: 243  of 300 sample #: 199 reconstruction error: 0.073396\n",
            "Epoch: 0 batch #: 244  of 300 sample #: 199 reconstruction error: 0.073225\n",
            "Epoch: 0 batch #: 245  of 300 sample #: 199 reconstruction error: 0.048723\n",
            "Epoch: 0 batch #: 246  of 300 sample #: 199 reconstruction error: 0.087279\n",
            "Epoch: 0 batch #: 247  of 300 sample #: 199 reconstruction error: 0.044154\n",
            "Epoch: 0 batch #: 248  of 300 sample #: 199 reconstruction error: 0.062310\n",
            "Epoch: 0 batch #: 249  of 300 sample #: 199 reconstruction error: 0.051148\n",
            "Epoch: 0 batch #: 250  of 300 sample #: 199 reconstruction error: 0.077847\n",
            "Epoch: 0 batch #: 251  of 300 sample #: 199 reconstruction error: 0.051342\n",
            "Epoch: 0 batch #: 252  of 300 sample #: 199 reconstruction error: 0.074414\n",
            "Epoch: 0 batch #: 253  of 300 sample #: 199 reconstruction error: 0.044095\n",
            "Epoch: 0 batch #: 254  of 300 sample #: 199 reconstruction error: 0.030848\n",
            "Epoch: 0 batch #: 255  of 300 sample #: 199 reconstruction error: 0.048485\n",
            "Epoch: 0 batch #: 256  of 300 sample #: 199 reconstruction error: 0.072388\n",
            "Epoch: 0 batch #: 257  of 300 sample #: 199 reconstruction error: 0.079389\n",
            "Epoch: 0 batch #: 258  of 300 sample #: 199 reconstruction error: 0.098473\n",
            "Epoch: 0 batch #: 259  of 300 sample #: 199 reconstruction error: 0.068355\n",
            "Epoch: 0 batch #: 260  of 300 sample #: 199 reconstruction error: 0.084373\n",
            "Epoch: 0 batch #: 261  of 300 sample #: 199 reconstruction error: 0.045636\n",
            "Epoch: 0 batch #: 262  of 300 sample #: 199 reconstruction error: 0.055504\n",
            "Epoch: 0 batch #: 263  of 300 sample #: 199 reconstruction error: 0.081613\n",
            "Epoch: 0 batch #: 264  of 300 sample #: 199 reconstruction error: 0.077381\n",
            "Epoch: 0 batch #: 265  of 300 sample #: 199 reconstruction error: 0.089641\n",
            "Epoch: 0 batch #: 266  of 300 sample #: 199 reconstruction error: 0.032452\n",
            "Epoch: 0 batch #: 267  of 300 sample #: 199 reconstruction error: 0.069167\n",
            "Epoch: 0 batch #: 268  of 300 sample #: 199 reconstruction error: 0.025580\n",
            "Epoch: 0 batch #: 269  of 300 sample #: 199 reconstruction error: 0.094575\n",
            "Epoch: 0 batch #: 270  of 300 sample #: 199 reconstruction error: 0.071422\n",
            "Epoch: 0 batch #: 271  of 300 sample #: 199 reconstruction error: 0.066837\n",
            "Epoch: 0 batch #: 272  of 300 sample #: 199 reconstruction error: 0.053863\n",
            "Epoch: 0 batch #: 273  of 300 sample #: 199 reconstruction error: 0.049670\n",
            "Epoch: 0 batch #: 274  of 300 sample #: 199 reconstruction error: 0.061609\n",
            "Epoch: 0 batch #: 275  of 300 sample #: 199 reconstruction error: 0.094914\n",
            "Epoch: 0 batch #: 276  of 300 sample #: 199 reconstruction error: 0.078668\n",
            "Epoch: 0 batch #: 277  of 300 sample #: 199 reconstruction error: 0.077206\n",
            "Epoch: 0 batch #: 278  of 300 sample #: 199 reconstruction error: 0.053177\n",
            "Epoch: 0 batch #: 279  of 300 sample #: 199 reconstruction error: 0.046309\n",
            "Epoch: 0 batch #: 280  of 300 sample #: 199 reconstruction error: 0.066850\n",
            "Epoch: 0 batch #: 281  of 300 sample #: 199 reconstruction error: 0.068917\n",
            "Epoch: 0 batch #: 282  of 300 sample #: 199 reconstruction error: 0.095677\n",
            "Epoch: 0 batch #: 283  of 300 sample #: 199 reconstruction error: 0.041800\n",
            "Epoch: 0 batch #: 284  of 300 sample #: 199 reconstruction error: 0.056840\n",
            "Epoch: 0 batch #: 285  of 300 sample #: 199 reconstruction error: 0.062194\n",
            "Epoch: 0 batch #: 286  of 300 sample #: 199 reconstruction error: 0.078947\n",
            "Epoch: 0 batch #: 287  of 300 sample #: 199 reconstruction error: 0.081864\n",
            "Epoch: 0 batch #: 288  of 300 sample #: 199 reconstruction error: 0.025206\n",
            "Epoch: 0 batch #: 289  of 300 sample #: 199 reconstruction error: 0.079194\n",
            "Epoch: 0 batch #: 290  of 300 sample #: 199 reconstruction error: 0.094127\n",
            "Epoch: 0 batch #: 291  of 300 sample #: 199 reconstruction error: 0.109464\n",
            "Epoch: 0 batch #: 292  of 300 sample #: 199 reconstruction error: 0.075324\n",
            "Epoch: 0 batch #: 293  of 300 sample #: 199 reconstruction error: 0.068715\n",
            "Epoch: 0 batch #: 294  of 300 sample #: 199 reconstruction error: 0.093155\n",
            "Epoch: 0 batch #: 295  of 300 sample #: 199 reconstruction error: 0.085611\n",
            "Epoch: 0 batch #: 296  of 300 sample #: 199 reconstruction error: 0.018810\n",
            "Epoch: 0 batch #: 297  of 300 sample #: 199 reconstruction error: 0.144533\n",
            "Epoch: 0 batch #: 298  of 300 sample #: 199 reconstruction error: 0.055704\n",
            "Epoch: 0 batch #: 299  of 300 sample #: 199 reconstruction error: 0.038506\n",
            "Epoch: 0 batch #: 300  of 300 sample #: 199 reconstruction error: 0.091683\n",
            "Epoch: 1 batch #: 301  of 300 sample #: 199 reconstruction error: 0.085277\n",
            "Epoch: 1 batch #: 302  of 300 sample #: 199 reconstruction error: 0.090314\n",
            "Epoch: 1 batch #: 303  of 300 sample #: 199 reconstruction error: 0.050071\n",
            "Epoch: 1 batch #: 304  of 300 sample #: 199 reconstruction error: 0.071370\n",
            "Epoch: 1 batch #: 305  of 300 sample #: 199 reconstruction error: 0.062368\n",
            "Epoch: 1 batch #: 306  of 300 sample #: 199 reconstruction error: 0.113450\n",
            "Epoch: 1 batch #: 307  of 300 sample #: 199 reconstruction error: 0.062889\n",
            "Epoch: 1 batch #: 308  of 300 sample #: 199 reconstruction error: 0.080478\n",
            "Epoch: 1 batch #: 309  of 300 sample #: 199 reconstruction error: 0.068810\n",
            "Epoch: 1 batch #: 310  of 300 sample #: 199 reconstruction error: 0.111655\n",
            "Epoch: 1 batch #: 311  of 300 sample #: 199 reconstruction error: 0.060599\n",
            "Epoch: 1 batch #: 312  of 300 sample #: 199 reconstruction error: 0.115782\n",
            "Epoch: 1 batch #: 313  of 300 sample #: 199 reconstruction error: 0.024968\n",
            "Epoch: 1 batch #: 314  of 300 sample #: 199 reconstruction error: 0.070605\n",
            "Epoch: 1 batch #: 315  of 300 sample #: 199 reconstruction error: 0.066467\n",
            "Epoch: 1 batch #: 316  of 300 sample #: 199 reconstruction error: 0.060108\n",
            "Epoch: 1 batch #: 317  of 300 sample #: 199 reconstruction error: 0.052283\n",
            "Epoch: 1 batch #: 318  of 300 sample #: 199 reconstruction error: 0.069860\n",
            "Epoch: 1 batch #: 319  of 300 sample #: 199 reconstruction error: 0.097424\n",
            "Epoch: 1 batch #: 320  of 300 sample #: 199 reconstruction error: 0.085414\n",
            "Epoch: 1 batch #: 321  of 300 sample #: 199 reconstruction error: 0.067875\n",
            "Epoch: 1 batch #: 322  of 300 sample #: 199 reconstruction error: 0.071792\n",
            "Epoch: 1 batch #: 323  of 300 sample #: 199 reconstruction error: 0.095144\n",
            "Epoch: 1 batch #: 324  of 300 sample #: 199 reconstruction error: 0.087064\n",
            "Epoch: 1 batch #: 325  of 300 sample #: 199 reconstruction error: 0.083798\n",
            "Epoch: 1 batch #: 326  of 300 sample #: 199 reconstruction error: 0.067334\n",
            "Epoch: 1 batch #: 327  of 300 sample #: 199 reconstruction error: 0.093392\n",
            "Epoch: 1 batch #: 328  of 300 sample #: 199 reconstruction error: 0.067164\n",
            "Epoch: 1 batch #: 329  of 300 sample #: 199 reconstruction error: 0.085200\n",
            "Epoch: 1 batch #: 330  of 300 sample #: 199 reconstruction error: 0.066324\n",
            "Epoch: 1 batch #: 331  of 300 sample #: 199 reconstruction error: 0.063697\n",
            "Epoch: 1 batch #: 332  of 300 sample #: 199 reconstruction error: 0.094114\n",
            "Epoch: 1 batch #: 333  of 300 sample #: 199 reconstruction error: 0.049243\n",
            "Epoch: 1 batch #: 334  of 300 sample #: 199 reconstruction error: 0.060219\n",
            "Epoch: 1 batch #: 335  of 300 sample #: 199 reconstruction error: 0.062895\n",
            "Epoch: 1 batch #: 336  of 300 sample #: 199 reconstruction error: 0.083543\n",
            "Epoch: 1 batch #: 337  of 300 sample #: 199 reconstruction error: 0.047087\n",
            "Epoch: 1 batch #: 338  of 300 sample #: 199 reconstruction error: 0.056813\n",
            "Epoch: 1 batch #: 339  of 300 sample #: 199 reconstruction error: 0.085204\n",
            "Epoch: 1 batch #: 340  of 300 sample #: 199 reconstruction error: 0.097373\n",
            "Epoch: 1 batch #: 341  of 300 sample #: 199 reconstruction error: 0.058985\n",
            "Epoch: 1 batch #: 342  of 300 sample #: 199 reconstruction error: 0.057591\n",
            "Epoch: 1 batch #: 343  of 300 sample #: 199 reconstruction error: 0.103650\n",
            "Epoch: 1 batch #: 344  of 300 sample #: 199 reconstruction error: 0.053048\n",
            "Epoch: 1 batch #: 345  of 300 sample #: 199 reconstruction error: 0.063793\n",
            "Epoch: 1 batch #: 346  of 300 sample #: 199 reconstruction error: 0.026239\n",
            "Epoch: 1 batch #: 347  of 300 sample #: 199 reconstruction error: 0.051565\n",
            "Epoch: 1 batch #: 348  of 300 sample #: 199 reconstruction error: 0.025420\n",
            "Epoch: 1 batch #: 349  of 300 sample #: 199 reconstruction error: 0.131786\n",
            "Epoch: 1 batch #: 350  of 300 sample #: 199 reconstruction error: 0.047647\n",
            "Epoch: 1 batch #: 351  of 300 sample #: 199 reconstruction error: 0.052767\n",
            "Epoch: 1 batch #: 352  of 300 sample #: 199 reconstruction error: 0.025141\n",
            "Epoch: 1 batch #: 353  of 300 sample #: 199 reconstruction error: 0.081447\n",
            "Epoch: 1 batch #: 354  of 300 sample #: 199 reconstruction error: 0.044221\n",
            "Epoch: 1 batch #: 355  of 300 sample #: 199 reconstruction error: 0.092873\n",
            "Epoch: 1 batch #: 356  of 300 sample #: 199 reconstruction error: 0.043901\n",
            "Epoch: 1 batch #: 357  of 300 sample #: 199 reconstruction error: 0.046924\n",
            "Epoch: 1 batch #: 358  of 300 sample #: 199 reconstruction error: 0.068014\n",
            "Epoch: 1 batch #: 359  of 300 sample #: 199 reconstruction error: 0.053685\n",
            "Epoch: 1 batch #: 360  of 300 sample #: 199 reconstruction error: 0.081099\n",
            "Epoch: 1 batch #: 361  of 300 sample #: 199 reconstruction error: 0.080132\n",
            "Epoch: 1 batch #: 362  of 300 sample #: 199 reconstruction error: 0.052537\n",
            "Epoch: 1 batch #: 363  of 300 sample #: 199 reconstruction error: 0.046798\n",
            "Epoch: 1 batch #: 364  of 300 sample #: 199 reconstruction error: 0.077219\n",
            "Epoch: 1 batch #: 365  of 300 sample #: 199 reconstruction error: 0.080292\n",
            "Epoch: 1 batch #: 366  of 300 sample #: 199 reconstruction error: 0.045155\n",
            "Epoch: 1 batch #: 367  of 300 sample #: 199 reconstruction error: 0.040236\n",
            "Epoch: 1 batch #: 368  of 300 sample #: 199 reconstruction error: 0.054020\n",
            "Epoch: 1 batch #: 369  of 300 sample #: 199 reconstruction error: 0.056557\n",
            "Epoch: 1 batch #: 370  of 300 sample #: 199 reconstruction error: 0.106968\n",
            "Epoch: 1 batch #: 371  of 300 sample #: 199 reconstruction error: 0.074694\n",
            "Epoch: 1 batch #: 372  of 300 sample #: 199 reconstruction error: 0.055573\n",
            "Epoch: 1 batch #: 373  of 300 sample #: 199 reconstruction error: 0.073698\n",
            "Epoch: 1 batch #: 374  of 300 sample #: 199 reconstruction error: 0.081399\n",
            "Epoch: 1 batch #: 375  of 300 sample #: 199 reconstruction error: 0.048948\n",
            "Epoch: 1 batch #: 376  of 300 sample #: 199 reconstruction error: 0.066031\n",
            "Epoch: 1 batch #: 377  of 300 sample #: 199 reconstruction error: 0.089969\n",
            "Epoch: 1 batch #: 378  of 300 sample #: 199 reconstruction error: 0.096701\n",
            "Epoch: 1 batch #: 379  of 300 sample #: 199 reconstruction error: 0.106091\n",
            "Epoch: 1 batch #: 380  of 300 sample #: 199 reconstruction error: 0.031601\n",
            "Epoch: 1 batch #: 381  of 300 sample #: 199 reconstruction error: 0.044727\n",
            "Epoch: 1 batch #: 382  of 300 sample #: 199 reconstruction error: 0.043171\n",
            "Epoch: 1 batch #: 383  of 300 sample #: 199 reconstruction error: 0.070913\n",
            "Epoch: 1 batch #: 384  of 300 sample #: 199 reconstruction error: 0.089878\n",
            "Epoch: 1 batch #: 385  of 300 sample #: 199 reconstruction error: 0.056032\n",
            "Epoch: 1 batch #: 386  of 300 sample #: 199 reconstruction error: 0.072458\n",
            "Epoch: 1 batch #: 387  of 300 sample #: 199 reconstruction error: 0.077006\n",
            "Epoch: 1 batch #: 388  of 300 sample #: 199 reconstruction error: 0.021499\n",
            "Epoch: 1 batch #: 389  of 300 sample #: 199 reconstruction error: 0.047043\n",
            "Epoch: 1 batch #: 390  of 300 sample #: 199 reconstruction error: 0.052686\n",
            "Epoch: 1 batch #: 391  of 300 sample #: 199 reconstruction error: 0.050877\n",
            "Epoch: 1 batch #: 392  of 300 sample #: 199 reconstruction error: 0.054414\n",
            "Epoch: 1 batch #: 393  of 300 sample #: 199 reconstruction error: 0.078293\n",
            "Epoch: 1 batch #: 394  of 300 sample #: 199 reconstruction error: 0.093512\n",
            "Epoch: 1 batch #: 395  of 300 sample #: 199 reconstruction error: 0.053140\n",
            "Epoch: 1 batch #: 396  of 300 sample #: 199 reconstruction error: 0.051239\n",
            "Epoch: 1 batch #: 397  of 300 sample #: 199 reconstruction error: 0.097007\n",
            "Epoch: 1 batch #: 398  of 300 sample #: 199 reconstruction error: 0.090870\n",
            "Epoch: 1 batch #: 399  of 300 sample #: 199 reconstruction error: 0.045256\n",
            "Epoch: 1 batch #: 400  of 300 sample #: 199 reconstruction error: 0.086869\n",
            "Epoch: 1 batch #: 401  of 300 sample #: 199 reconstruction error: 0.068725\n",
            "Epoch: 1 batch #: 402  of 300 sample #: 199 reconstruction error: 0.081221\n",
            "Epoch: 1 batch #: 403  of 300 sample #: 199 reconstruction error: 0.078304\n",
            "Epoch: 1 batch #: 404  of 300 sample #: 199 reconstruction error: 0.060513\n",
            "Epoch: 1 batch #: 405  of 300 sample #: 199 reconstruction error: 0.057655\n",
            "Epoch: 1 batch #: 406  of 300 sample #: 199 reconstruction error: 0.097558\n",
            "Epoch: 1 batch #: 407  of 300 sample #: 199 reconstruction error: 0.131670\n",
            "Epoch: 1 batch #: 408  of 300 sample #: 199 reconstruction error: 0.055727\n",
            "Epoch: 1 batch #: 409  of 300 sample #: 199 reconstruction error: 0.130423\n",
            "Epoch: 1 batch #: 410  of 300 sample #: 199 reconstruction error: 0.057021\n",
            "Epoch: 1 batch #: 411  of 300 sample #: 199 reconstruction error: 0.088482\n",
            "Epoch: 1 batch #: 412  of 300 sample #: 199 reconstruction error: 0.038180\n",
            "Epoch: 1 batch #: 413  of 300 sample #: 199 reconstruction error: 0.079031\n",
            "Epoch: 1 batch #: 414  of 300 sample #: 199 reconstruction error: 0.077300\n",
            "Epoch: 1 batch #: 415  of 300 sample #: 199 reconstruction error: 0.055539\n",
            "Epoch: 1 batch #: 416  of 300 sample #: 199 reconstruction error: 0.043427\n",
            "Epoch: 1 batch #: 417  of 300 sample #: 199 reconstruction error: 0.040912\n",
            "Epoch: 1 batch #: 418  of 300 sample #: 199 reconstruction error: 0.067113\n",
            "Epoch: 1 batch #: 419  of 300 sample #: 199 reconstruction error: 0.119922\n",
            "Epoch: 1 batch #: 420  of 300 sample #: 199 reconstruction error: 0.069273\n",
            "Epoch: 1 batch #: 421  of 300 sample #: 199 reconstruction error: 0.040412\n",
            "Epoch: 1 batch #: 422  of 300 sample #: 199 reconstruction error: 0.088632\n",
            "Epoch: 1 batch #: 423  of 300 sample #: 199 reconstruction error: 0.065213\n",
            "Epoch: 1 batch #: 424  of 300 sample #: 199 reconstruction error: 0.057117\n",
            "Epoch: 1 batch #: 425  of 300 sample #: 199 reconstruction error: 0.043030\n",
            "Epoch: 1 batch #: 426  of 300 sample #: 199 reconstruction error: 0.085562\n",
            "Epoch: 1 batch #: 427  of 300 sample #: 199 reconstruction error: 0.088374\n",
            "Epoch: 1 batch #: 428  of 300 sample #: 199 reconstruction error: 0.074519\n",
            "Epoch: 1 batch #: 429  of 300 sample #: 199 reconstruction error: 0.051835\n",
            "Epoch: 1 batch #: 430  of 300 sample #: 199 reconstruction error: 0.077180\n",
            "Epoch: 1 batch #: 431  of 300 sample #: 199 reconstruction error: 0.069980\n",
            "Epoch: 1 batch #: 432  of 300 sample #: 199 reconstruction error: 0.055489\n",
            "Epoch: 1 batch #: 433  of 300 sample #: 199 reconstruction error: 0.063343\n",
            "Epoch: 1 batch #: 434  of 300 sample #: 199 reconstruction error: 0.095462\n",
            "Epoch: 1 batch #: 435  of 300 sample #: 199 reconstruction error: 0.086495\n",
            "Epoch: 1 batch #: 436  of 300 sample #: 199 reconstruction error: 0.092070\n",
            "Epoch: 1 batch #: 437  of 300 sample #: 199 reconstruction error: 0.073448\n",
            "Epoch: 1 batch #: 438  of 300 sample #: 199 reconstruction error: 0.078339\n",
            "Epoch: 1 batch #: 439  of 300 sample #: 199 reconstruction error: 0.123840\n",
            "Epoch: 1 batch #: 440  of 300 sample #: 199 reconstruction error: 0.081163\n",
            "Epoch: 1 batch #: 441  of 300 sample #: 199 reconstruction error: 0.062347\n",
            "Epoch: 1 batch #: 442  of 300 sample #: 199 reconstruction error: 0.059640\n",
            "Epoch: 1 batch #: 443  of 300 sample #: 199 reconstruction error: 0.044066\n",
            "Epoch: 1 batch #: 444  of 300 sample #: 199 reconstruction error: 0.060370\n",
            "Epoch: 1 batch #: 445  of 300 sample #: 199 reconstruction error: 0.079516\n",
            "Epoch: 1 batch #: 446  of 300 sample #: 199 reconstruction error: 0.108427\n",
            "Epoch: 1 batch #: 447  of 300 sample #: 199 reconstruction error: 0.080579\n",
            "Epoch: 1 batch #: 448  of 300 sample #: 199 reconstruction error: 0.087464\n",
            "Epoch: 1 batch #: 449  of 300 sample #: 199 reconstruction error: 0.042957\n",
            "Epoch: 1 batch #: 450  of 300 sample #: 199 reconstruction error: 0.035166\n",
            "Epoch: 1 batch #: 451  of 300 sample #: 199 reconstruction error: 0.106982\n",
            "Epoch: 1 batch #: 452  of 300 sample #: 199 reconstruction error: 0.081258\n",
            "Epoch: 1 batch #: 453  of 300 sample #: 199 reconstruction error: 0.063408\n",
            "Epoch: 1 batch #: 454  of 300 sample #: 199 reconstruction error: 0.061332\n",
            "Epoch: 1 batch #: 455  of 300 sample #: 199 reconstruction error: 0.071206\n",
            "Epoch: 1 batch #: 456  of 300 sample #: 199 reconstruction error: 0.059445\n",
            "Epoch: 1 batch #: 457  of 300 sample #: 199 reconstruction error: 0.067399\n",
            "Epoch: 1 batch #: 458  of 300 sample #: 199 reconstruction error: 0.070014\n",
            "Epoch: 1 batch #: 459  of 300 sample #: 199 reconstruction error: 0.058811\n",
            "Epoch: 1 batch #: 460  of 300 sample #: 199 reconstruction error: 0.082993\n",
            "Epoch: 1 batch #: 461  of 300 sample #: 199 reconstruction error: 0.089393\n",
            "Epoch: 1 batch #: 462  of 300 sample #: 199 reconstruction error: 0.104140\n",
            "Epoch: 1 batch #: 463  of 300 sample #: 199 reconstruction error: 0.039232\n",
            "Epoch: 1 batch #: 464  of 300 sample #: 199 reconstruction error: 0.055146\n",
            "Epoch: 1 batch #: 465  of 300 sample #: 199 reconstruction error: 0.063503\n",
            "Epoch: 1 batch #: 466  of 300 sample #: 199 reconstruction error: 0.051472\n",
            "Epoch: 1 batch #: 467  of 300 sample #: 199 reconstruction error: 0.097684\n",
            "Epoch: 1 batch #: 468  of 300 sample #: 199 reconstruction error: 0.046800\n",
            "Epoch: 1 batch #: 469  of 300 sample #: 199 reconstruction error: 0.033259\n",
            "Epoch: 1 batch #: 470  of 300 sample #: 199 reconstruction error: 0.042837\n",
            "Epoch: 1 batch #: 471  of 300 sample #: 199 reconstruction error: 0.030486\n",
            "Epoch: 1 batch #: 472  of 300 sample #: 199 reconstruction error: 0.037647\n",
            "Epoch: 1 batch #: 473  of 300 sample #: 199 reconstruction error: 0.070563\n",
            "Epoch: 1 batch #: 474  of 300 sample #: 199 reconstruction error: 0.100240\n",
            "Epoch: 1 batch #: 475  of 300 sample #: 199 reconstruction error: 0.077935\n",
            "Epoch: 1 batch #: 476  of 300 sample #: 199 reconstruction error: 0.051689\n",
            "Epoch: 1 batch #: 477  of 300 sample #: 199 reconstruction error: 0.033511\n",
            "Epoch: 1 batch #: 478  of 300 sample #: 199 reconstruction error: 0.093981\n",
            "Epoch: 1 batch #: 479  of 300 sample #: 199 reconstruction error: 0.069822\n",
            "Epoch: 1 batch #: 480  of 300 sample #: 199 reconstruction error: 0.081640\n",
            "Epoch: 1 batch #: 481  of 300 sample #: 199 reconstruction error: 0.084698\n",
            "Epoch: 1 batch #: 482  of 300 sample #: 199 reconstruction error: 0.066442\n",
            "Epoch: 1 batch #: 483  of 300 sample #: 199 reconstruction error: 0.132148\n",
            "Epoch: 1 batch #: 484  of 300 sample #: 199 reconstruction error: 0.063348\n",
            "Epoch: 1 batch #: 485  of 300 sample #: 199 reconstruction error: 0.093867\n",
            "Epoch: 1 batch #: 486  of 300 sample #: 199 reconstruction error: 0.091449\n",
            "Epoch: 1 batch #: 487  of 300 sample #: 199 reconstruction error: 0.046674\n",
            "Epoch: 1 batch #: 488  of 300 sample #: 199 reconstruction error: 0.111055\n",
            "Epoch: 1 batch #: 489  of 300 sample #: 199 reconstruction error: 0.066397\n",
            "Epoch: 1 batch #: 490  of 300 sample #: 199 reconstruction error: 0.065754\n",
            "Epoch: 1 batch #: 491  of 300 sample #: 199 reconstruction error: 0.129357\n",
            "Epoch: 1 batch #: 492  of 300 sample #: 199 reconstruction error: 0.099446\n",
            "Epoch: 1 batch #: 493  of 300 sample #: 199 reconstruction error: 0.115444\n",
            "Epoch: 1 batch #: 494  of 300 sample #: 199 reconstruction error: 0.064998\n",
            "Epoch: 1 batch #: 495  of 300 sample #: 199 reconstruction error: 0.049400\n",
            "Epoch: 1 batch #: 496  of 300 sample #: 199 reconstruction error: 0.058237\n",
            "Epoch: 1 batch #: 497  of 300 sample #: 199 reconstruction error: 0.048332\n",
            "Epoch: 1 batch #: 498  of 300 sample #: 199 reconstruction error: 0.094461\n",
            "Epoch: 1 batch #: 499  of 300 sample #: 199 reconstruction error: 0.071090\n",
            "Epoch: 1 batch #: 500  of 300 sample #: 199 reconstruction error: 0.099475\n",
            "Epoch: 1 batch #: 501  of 300 sample #: 199 reconstruction error: 0.093684\n",
            "Epoch: 1 batch #: 502  of 300 sample #: 199 reconstruction error: 0.036291\n",
            "Epoch: 1 batch #: 503  of 300 sample #: 199 reconstruction error: 0.076901\n",
            "Epoch: 1 batch #: 504  of 300 sample #: 199 reconstruction error: 0.054696\n",
            "Epoch: 1 batch #: 505  of 300 sample #: 199 reconstruction error: 0.021095\n",
            "Epoch: 1 batch #: 506  of 300 sample #: 199 reconstruction error: 0.069480\n",
            "Epoch: 1 batch #: 507  of 300 sample #: 199 reconstruction error: 0.092592\n",
            "Epoch: 1 batch #: 508  of 300 sample #: 199 reconstruction error: 0.043611\n",
            "Epoch: 1 batch #: 509  of 300 sample #: 199 reconstruction error: 0.034112\n",
            "Epoch: 1 batch #: 510  of 300 sample #: 199 reconstruction error: 0.107850\n",
            "Epoch: 1 batch #: 511  of 300 sample #: 199 reconstruction error: 0.102588\n",
            "Epoch: 1 batch #: 512  of 300 sample #: 199 reconstruction error: 0.079785\n",
            "Epoch: 1 batch #: 513  of 300 sample #: 199 reconstruction error: 0.094195\n",
            "Epoch: 1 batch #: 514  of 300 sample #: 199 reconstruction error: 0.082856\n",
            "Epoch: 1 batch #: 515  of 300 sample #: 199 reconstruction error: 0.029717\n",
            "Epoch: 1 batch #: 516  of 300 sample #: 199 reconstruction error: 0.103708\n",
            "Epoch: 1 batch #: 517  of 300 sample #: 199 reconstruction error: 0.092060\n",
            "Epoch: 1 batch #: 518  of 300 sample #: 199 reconstruction error: 0.064740\n",
            "Epoch: 1 batch #: 519  of 300 sample #: 199 reconstruction error: 0.082065\n",
            "Epoch: 1 batch #: 520  of 300 sample #: 199 reconstruction error: 0.059881\n",
            "Epoch: 1 batch #: 521  of 300 sample #: 199 reconstruction error: 0.101188\n",
            "Epoch: 1 batch #: 522  of 300 sample #: 199 reconstruction error: 0.091808\n",
            "Epoch: 1 batch #: 523  of 300 sample #: 199 reconstruction error: 0.080676\n",
            "Epoch: 1 batch #: 524  of 300 sample #: 199 reconstruction error: 0.069073\n",
            "Epoch: 1 batch #: 525  of 300 sample #: 199 reconstruction error: 0.068983\n",
            "Epoch: 1 batch #: 526  of 300 sample #: 199 reconstruction error: 0.109010\n",
            "Epoch: 1 batch #: 527  of 300 sample #: 199 reconstruction error: 0.083028\n",
            "Epoch: 1 batch #: 528  of 300 sample #: 199 reconstruction error: 0.066286\n",
            "Epoch: 1 batch #: 529  of 300 sample #: 199 reconstruction error: 0.079101\n",
            "Epoch: 1 batch #: 530  of 300 sample #: 199 reconstruction error: 0.036564\n",
            "Epoch: 1 batch #: 531  of 300 sample #: 199 reconstruction error: 0.022363\n",
            "Epoch: 1 batch #: 532  of 300 sample #: 199 reconstruction error: 0.080118\n",
            "Epoch: 1 batch #: 533  of 300 sample #: 199 reconstruction error: 0.092669\n",
            "Epoch: 1 batch #: 534  of 300 sample #: 199 reconstruction error: 0.063181\n",
            "Epoch: 1 batch #: 535  of 300 sample #: 199 reconstruction error: 0.064108\n",
            "Epoch: 1 batch #: 536  of 300 sample #: 199 reconstruction error: 0.093734\n",
            "Epoch: 1 batch #: 537  of 300 sample #: 199 reconstruction error: 0.085187\n",
            "Epoch: 1 batch #: 538  of 300 sample #: 199 reconstruction error: 0.112394\n",
            "Epoch: 1 batch #: 539  of 300 sample #: 199 reconstruction error: 0.033482\n",
            "Epoch: 1 batch #: 540  of 300 sample #: 199 reconstruction error: 0.102218\n",
            "Epoch: 1 batch #: 541  of 300 sample #: 199 reconstruction error: 0.087973\n",
            "Epoch: 1 batch #: 542  of 300 sample #: 199 reconstruction error: 0.074432\n",
            "Epoch: 1 batch #: 543  of 300 sample #: 199 reconstruction error: 0.077083\n",
            "Epoch: 1 batch #: 544  of 300 sample #: 199 reconstruction error: 0.078372\n",
            "Epoch: 1 batch #: 545  of 300 sample #: 199 reconstruction error: 0.048307\n",
            "Epoch: 1 batch #: 546  of 300 sample #: 199 reconstruction error: 0.099374\n",
            "Epoch: 1 batch #: 547  of 300 sample #: 199 reconstruction error: 0.055824\n",
            "Epoch: 1 batch #: 548  of 300 sample #: 199 reconstruction error: 0.060379\n",
            "Epoch: 1 batch #: 549  of 300 sample #: 199 reconstruction error: 0.056565\n",
            "Epoch: 1 batch #: 550  of 300 sample #: 199 reconstruction error: 0.088452\n",
            "Epoch: 1 batch #: 551  of 300 sample #: 199 reconstruction error: 0.050012\n",
            "Epoch: 1 batch #: 552  of 300 sample #: 199 reconstruction error: 0.073678\n",
            "Epoch: 1 batch #: 553  of 300 sample #: 199 reconstruction error: 0.060257\n",
            "Epoch: 1 batch #: 554  of 300 sample #: 199 reconstruction error: 0.033014\n",
            "Epoch: 1 batch #: 555  of 300 sample #: 199 reconstruction error: 0.058959\n",
            "Epoch: 1 batch #: 556  of 300 sample #: 199 reconstruction error: 0.073043\n",
            "Epoch: 1 batch #: 557  of 300 sample #: 199 reconstruction error: 0.077768\n",
            "Epoch: 1 batch #: 558  of 300 sample #: 199 reconstruction error: 0.107276\n",
            "Epoch: 1 batch #: 559  of 300 sample #: 199 reconstruction error: 0.073112\n",
            "Epoch: 1 batch #: 560  of 300 sample #: 199 reconstruction error: 0.097833\n",
            "Epoch: 1 batch #: 561  of 300 sample #: 199 reconstruction error: 0.035517\n",
            "Epoch: 1 batch #: 562  of 300 sample #: 199 reconstruction error: 0.056149\n",
            "Epoch: 1 batch #: 563  of 300 sample #: 199 reconstruction error: 0.067983\n",
            "Epoch: 1 batch #: 564  of 300 sample #: 199 reconstruction error: 0.068992\n",
            "Epoch: 1 batch #: 565  of 300 sample #: 199 reconstruction error: 0.073830\n",
            "Epoch: 1 batch #: 566  of 300 sample #: 199 reconstruction error: 0.040115\n",
            "Epoch: 1 batch #: 567  of 300 sample #: 199 reconstruction error: 0.057682\n",
            "Epoch: 1 batch #: 568  of 300 sample #: 199 reconstruction error: 0.024090\n",
            "Epoch: 1 batch #: 569  of 300 sample #: 199 reconstruction error: 0.089233\n",
            "Epoch: 1 batch #: 570  of 300 sample #: 199 reconstruction error: 0.065140\n",
            "Epoch: 1 batch #: 571  of 300 sample #: 199 reconstruction error: 0.052906\n",
            "Epoch: 1 batch #: 572  of 300 sample #: 199 reconstruction error: 0.056944\n",
            "Epoch: 1 batch #: 573  of 300 sample #: 199 reconstruction error: 0.042242\n",
            "Epoch: 1 batch #: 574  of 300 sample #: 199 reconstruction error: 0.046318\n",
            "Epoch: 1 batch #: 575  of 300 sample #: 199 reconstruction error: 0.101452\n",
            "Epoch: 1 batch #: 576  of 300 sample #: 199 reconstruction error: 0.076838\n",
            "Epoch: 1 batch #: 577  of 300 sample #: 199 reconstruction error: 0.092687\n",
            "Epoch: 1 batch #: 578  of 300 sample #: 199 reconstruction error: 0.047420\n",
            "Epoch: 1 batch #: 579  of 300 sample #: 199 reconstruction error: 0.043838\n",
            "Epoch: 1 batch #: 580  of 300 sample #: 199 reconstruction error: 0.068885\n",
            "Epoch: 1 batch #: 581  of 300 sample #: 199 reconstruction error: 0.070217\n",
            "Epoch: 1 batch #: 582  of 300 sample #: 199 reconstruction error: 0.093806\n",
            "Epoch: 1 batch #: 583  of 300 sample #: 199 reconstruction error: 0.046812\n",
            "Epoch: 1 batch #: 584  of 300 sample #: 199 reconstruction error: 0.044390\n",
            "Epoch: 1 batch #: 585  of 300 sample #: 199 reconstruction error: 0.071573\n",
            "Epoch: 1 batch #: 586  of 300 sample #: 199 reconstruction error: 0.084544\n",
            "Epoch: 1 batch #: 587  of 300 sample #: 199 reconstruction error: 0.078187\n",
            "Epoch: 1 batch #: 588  of 300 sample #: 199 reconstruction error: 0.031169\n",
            "Epoch: 1 batch #: 589  of 300 sample #: 199 reconstruction error: 0.065079\n",
            "Epoch: 1 batch #: 590  of 300 sample #: 199 reconstruction error: 0.098374\n",
            "Epoch: 1 batch #: 591  of 300 sample #: 199 reconstruction error: 0.109789\n",
            "Epoch: 1 batch #: 592  of 300 sample #: 199 reconstruction error: 0.074044\n",
            "Epoch: 1 batch #: 593  of 300 sample #: 199 reconstruction error: 0.067285\n",
            "Epoch: 1 batch #: 594  of 300 sample #: 199 reconstruction error: 0.095496\n",
            "Epoch: 1 batch #: 595  of 300 sample #: 199 reconstruction error: 0.086472\n",
            "Epoch: 1 batch #: 596  of 300 sample #: 199 reconstruction error: 0.029234\n",
            "Epoch: 1 batch #: 597  of 300 sample #: 199 reconstruction error: 0.147679\n",
            "Epoch: 1 batch #: 598  of 300 sample #: 199 reconstruction error: 0.062296\n",
            "Epoch: 1 batch #: 599  of 300 sample #: 199 reconstruction error: 0.050541\n",
            "Epoch: 1 batch #: 600  of 300 sample #: 199 reconstruction error: 0.088757\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3XDohd4m8OvJ"
      },
      "source": [
        "Let's take a look at the errors at the end of each batch:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "da2rxJAc8OvJ",
        "outputId": "6541577f-a47b-4c0e-a2a1-4f42f14d0b90"
      },
      "source": [
        "plt.plot(errors)\n",
        "plt.xlabel(\"Batch Number\")\n",
        "plt.ylabel(\"Error\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h5mmDHI78OvJ"
      },
      "source": [
        "What is the final weight matrix $W$ after training?\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "or7kg1RR8OvJ",
        "outputId": "16e8a8b4-2522-486b-9ff3-93a18bb4da75"
      },
      "source": [
        "print(W.numpy()) # a weight matrix of shape (50,784)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[-0.40999976 -0.38099977 -0.2779999  ... -0.3249999  -0.23700005\n",
            "  -0.27999988]\n",
            " [-0.4959996  -0.3599998  -0.2969999  ... -0.28499994 -0.17800002\n",
            "  -0.20400004]\n",
            " [-0.45499977 -0.32999983 -0.33599988 ... -0.3439999  -0.22100003\n",
            "  -0.27399996]\n",
            " ...\n",
            " [-0.45799974 -0.40399972 -0.3429999  ... -0.2959999  -0.271\n",
            "  -0.29299995]\n",
            " [-0.36799982 -0.3789998  -0.2979999  ... -0.26299998 -0.23700005\n",
            "  -0.21500003]\n",
            " [-0.38999978 -0.43599978 -0.29299995 ... -0.3239999  -0.24400005\n",
            "  -0.25100002]]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}