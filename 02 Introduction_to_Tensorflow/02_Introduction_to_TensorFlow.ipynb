{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "02 Introduction_to_TensorFlow.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "izaAYfDGveRj"
      },
      "source": [
        "# **Introduction to Tensorflow**\n",
        "\n",
        "\n",
        "<img src = \"https://miro.medium.com/max/1025/1*vWsIxYG3EkR7C_lsziqPFQ.png\">\n",
        "\n",
        "## **What is Tensor?**\n",
        "\n",
        "A tensor is an N-dimensional array of data\n",
        "\n",
        "<img src = \"https://raw.githubusercontent.com/mhuzaifadev/ml_zero_to_hero/master/tensor.png?token=AMSGSQZDZZOG2HNLKMX7SGS72X4Q4\">\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fKH1OqniyoLU"
      },
      "source": [
        "## **Components of TensorFlow: Tensors and Variables**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YdiTAFMqy21a",
        "outputId": "078a9b90-55a7-4cff-9ebd-0ea89348ed8f"
      },
      "source": [
        "#Importing Tensorflow\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "\n",
        "import numpy as np\n",
        "print(np.__version__)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.3.0\n",
            "1.18.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QMi_8GEWzf7i"
      },
      "source": [
        "**Producing Constant Tensors**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xRew53kesJXo",
        "outputId": "c3c51947-35f0-4ea0-9eda-b26bfcaaa4b1"
      },
      "source": [
        "x = tf.constant([\n",
        "                 [3,6,9],\n",
        "                 [6,8,11]\n",
        "])\n",
        "x"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 3), dtype=int32, numpy=\n",
              "array([[ 3,  6,  9],\n",
              "       [ 6,  8, 11]], dtype=int32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aWCJYXq1zlW5"
      },
      "source": [
        "**Tensors can be sliced**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iaMgRjp4zlEP",
        "outputId": "0677546d-8ba8-43ab-fcc0-4a8cb1e5f1a0"
      },
      "source": [
        "y = x[:,1]\n",
        "y"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2,), dtype=int32, numpy=array([6, 8], dtype=int32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TvjyqmeqzyW_"
      },
      "source": [
        "**Tensors can be reshaped**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LcXA-aNqz5qH",
        "outputId": "fe00d12a-7c6f-47a3-c697-8da8026230fd"
      },
      "source": [
        "y = tf.reshape(x,[3,2])\n",
        "y"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3, 2), dtype=int32, numpy=\n",
              "array([[ 3,  6],\n",
              "       [ 9,  6],\n",
              "       [ 8, 11]], dtype=int32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q_QV4A-y6NVQ"
      },
      "source": [
        "**Here is a \"scalar\" or \"rank-0\" tensor . A scalar contains a single value, and no \"axes\".**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "agBm1YDH6NjN",
        "outputId": "b244af27-e8fa-479b-ef60-451c029dedd8"
      },
      "source": [
        "# This will be an int32 tensor by default; see \"dtypes\" below.\n",
        "rank_0_tensor = tf.constant(4)\n",
        "print(rank_0_tensor)"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(4, shape=(), dtype=int32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wPMnFMEq6U_n"
      },
      "source": [
        "**A \"vector\" or \"rank-1\" tensor is like a list of values. A vector has 1-axis:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aTJWv07b6VJB",
        "outputId": "d07bbf37-6a9e-465d-a578-96d79d0bf516"
      },
      "source": [
        "# Let's make this a float tensor.\n",
        "rank_1_tensor = tf.constant([2.0, 3.0, 4.0])\n",
        "print(rank_1_tensor)"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor([2. 3. 4.], shape=(3,), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xberh3lo6bIw"
      },
      "source": [
        "**A \"matrix\" or \"rank-2\" tensor has 2-axes:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0il8RXrK6ghK",
        "outputId": "f0ca98bf-c319-4a80-85c4-53f3128c8492"
      },
      "source": [
        "# If we want to be specific, we can set the dtype (see below) at creation time\n",
        "rank_2_tensor = tf.constant([[1, 2],\n",
        "                             [3, 4],\n",
        "                             [5, 6]], dtype= float)\n",
        "                                      \n",
        "print(rank_2_tensor)"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[1. 2.]\n",
            " [3. 4.]\n",
            " [5. 6.]], shape=(3, 2), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C3TWseR87R19"
      },
      "source": [
        "<img src = \"https://raw.githubusercontent.com/mhuzaifadev/ml_zero_to_hero/master/tens.png?token=AMSGSQ3F37MUKV2OSZYW5L272YBGI\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JSQ-oXux7Yj_"
      },
      "source": [
        "**Tensors may have more axes, here is a tensor with 3-axes:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MmNA-C097dDD",
        "outputId": "cebb7580-92dd-4114-ab1a-6c411d39a732"
      },
      "source": [
        "# There can be an arbitrary number of\n",
        "# axes (sometimes called \"dimensions\")\n",
        "rank_3_tensor = tf.constant([\n",
        "  [[0, 1, 2, 3, 4],\n",
        "   [5, 6, 7, 8, 9]],\n",
        "  [[10, 11, 12, 13, 14],\n",
        "   [15, 16, 17, 18, 19]],\n",
        "  [[20, 21, 22, 23, 24],\n",
        "   [25, 26, 27, 28, 29]],])\n",
        "                    \n",
        "print(rank_3_tensor)"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[[ 0  1  2  3  4]\n",
            "  [ 5  6  7  8  9]]\n",
            "\n",
            " [[10 11 12 13 14]\n",
            "  [15 16 17 18 19]]\n",
            "\n",
            " [[20 21 22 23 24]\n",
            "  [25 26 27 28 29]]], shape=(3, 2, 5), dtype=int32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SHQe4_4m8AOX"
      },
      "source": [
        "<img src =\"https://raw.githubusercontent.com/mhuzaifadev/ml_zero_to_hero/master/3axistensor.png?token=AMSGSQ7WYXWWTHZLZ6HA2NS72YBR2\">\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "trbjnRZK8mXf"
      },
      "source": [
        "**You can convert a tensor to a NumPy array either using np.array or the tensor.numpy method:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ad_kV2Hq8p_j",
        "outputId": "a91c7998-d4ea-4685-f369-45f9b9465d61"
      },
      "source": [
        "# Convert a tensor to a NumPy array using `np.array` method\n",
        "np.array(rank_2_tensor)"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1., 2.],\n",
              "       [3., 4.],\n",
              "       [5., 6.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UuHGLNID8qDx",
        "outputId": "fcdf8a0a-5757-4479-d551-106793f0e687"
      },
      "source": [
        "# Convert a tensor to a NumPy array using `tensor.numpy` method\n",
        "rank_2_tensor.numpy"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method _EagerTensorBase.numpy of <tf.Tensor: shape=(3, 2), dtype=float32, numpy=\n",
              "array([[1., 2.],\n",
              "       [3., 4.],\n",
              "       [5., 6.]], dtype=float32)>>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jpqj971898o5"
      },
      "source": [
        "**We can do basic math on tensors, including addition, element-wise multiplication, and matrix multiplication.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m3OMptRh97SA",
        "outputId": "31e3cf91-0698-49cd-f32b-8276e402db2f"
      },
      "source": [
        "a = tf.constant([[1, 2],\n",
        "                 [3, 4]])\n",
        "b = tf.constant([[1, 1],\n",
        "                 [1, 1]]) # Could have also said `tf.ones([2,2])`\n",
        "\n",
        "print(tf.add(a, b), \"\\n\")\n",
        "print(tf.multiply(a, b), \"\\n\")\n",
        "print(tf.matmul(a, b), \"\\n\")"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[2 3]\n",
            " [4 5]], shape=(2, 2), dtype=int32) \n",
            "\n",
            "tf.Tensor(\n",
            "[[1 2]\n",
            " [3 4]], shape=(2, 2), dtype=int32) \n",
            "\n",
            "tf.Tensor(\n",
            "[[3 3]\n",
            " [7 7]], shape=(2, 2), dtype=int32) \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2phbMZjB-LMc",
        "outputId": "6d7bb41a-43f7-4a31-d527-847ca237fb14"
      },
      "source": [
        "print(a + b, \"\\n\") # element-wise addition\n",
        "print(a * b, \"\\n\") # element-wise multiplication\n",
        "print(a @ b, \"\\n\") # matrix multiplication"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[2 3]\n",
            " [4 5]], shape=(2, 2), dtype=int32) \n",
            "\n",
            "tf.Tensor(\n",
            "[[1 2]\n",
            " [3 4]], shape=(2, 2), dtype=int32) \n",
            "\n",
            "tf.Tensor(\n",
            "[[3 3]\n",
            " [7 7]], shape=(2, 2), dtype=int32) \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sw19Ep4k-8vV"
      },
      "source": [
        "**Tensors are used in all kinds of operations (ops).**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tf3bny3V-_Sv",
        "outputId": "04b7ee04-2ff7-4285-915d-88f05c24acfc"
      },
      "source": [
        "c = tf.constant([[4.0, 5.0], [10.0, 1.0]])\n",
        "\n",
        "# Find the largest value\n",
        "print(tf.reduce_max(c))\n",
        "\n",
        "# Find the index of the largest value\n",
        "print(tf.math.argmax(c))\n",
        "\n",
        "#Compute the Softmax\n",
        "tf.nn.softmax(c)"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(10.0, shape=(), dtype=float32)\n",
            "tf.Tensor([1 0], shape=(2,), dtype=int64)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
              "array([[2.6894143e-01, 7.3105860e-01],\n",
              "       [9.9987662e-01, 1.2339458e-04]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v1_d-cAWAT2D"
      },
      "source": [
        "## **About Shapes**\n",
        "\n",
        "Tensors have shapes.  Some vocabulary:\n",
        "\n",
        "* **Shape**: The length (number of elements) of each of the dimensions of a tensor.\n",
        "* **Rank**: Number of tensor dimensions.  A scalar has rank 0, a vector has rank 1, a matrix is rank 2.\n",
        "* **Axis** or **Dimension**: A particular dimension of a tensor.\n",
        "* **Size**: The total number of items in the tensor, the product shape vector\n",
        "\n",
        "Note: Although you may see reference to a \"tensor of two dimensions\", a rank-2 tensor does not usually describe a 2D space.\n",
        "\n",
        "Tensors and `tf.TensorShape` objects have convenient properties for accessing these:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SEV8sI7kAZmV"
      },
      "source": [
        "rank_4_tensor = tf.zeros([3, 2, 4, 5])"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BPBUQkpJBEjn",
        "outputId": "d065fb1a-47e6-4e90-fd0f-21c113cc1e73"
      },
      "source": [
        "rank_4_tensor"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3, 2, 4, 5), dtype=float32, numpy=\n",
              "array([[[[0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0.]]],\n",
              "\n",
              "\n",
              "       [[[0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0.]]],\n",
              "\n",
              "\n",
              "       [[[0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0.]]]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IW2KHCkIA3P1"
      },
      "source": [
        "<img src = \"https://raw.githubusercontent.com/mhuzaifadev/ml_zero_to_hero/master/shapes.png?token=AMSGSQ6JJPMYB35OHL6C2F272YECG\">\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nn7UdITqA8Dh",
        "outputId": "180ea7f1-6565-473b-cde4-cf6b8ba9b3d6"
      },
      "source": [
        "print(\"Type of every element:\", rank_4_tensor.dtype)\n",
        "print(\"Number of dimensions:\", rank_4_tensor.ndim)\n",
        "print(\"Shape of tensor:\", rank_4_tensor.shape)\n",
        "print(\"Elements along axis 0 of tensor:\", rank_4_tensor.shape[0])\n",
        "print(\"Elements along the last axis of tensor:\", rank_4_tensor.shape[-1])\n",
        "print(\"Total number of elements (3*2*4*5): \", tf.size(rank_4_tensor).numpy())"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Type of every element: <dtype: 'float32'>\n",
            "Number of dimensions: 4\n",
            "Shape of tensor: (3, 2, 4, 5)\n",
            "Elements along axis 0 of tensor: 3\n",
            "Elements along the last axis of tensor: 5\n",
            "Total number of elements (3*2*4*5):  120\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZweEVM6WBPuk"
      },
      "source": [
        "While axes are often referred to by their indices, you should always keep track of the meaning of each. Often axes are ordered from global to local: The batch axis first, followed by spatial dimensions, and features for each location last. This way feature vectors are contiguous regions of memory.\n",
        "\n",
        "<img src = \"https://raw.githubusercontent.com/mhuzaifadev/ml_zero_to_hero/master/rank4.png?token=AMSGSQ6PYTFUJUQO6VIO2OK72YER2\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fJ0Hiqg8B--a"
      },
      "source": [
        "### **Single-axis indexing**\n",
        "\n",
        "TensorFlow follow standard python indexing rules, similar to indexing a list or a string in python, and the bacic rules for numpy indexing.\n",
        "\n",
        "indexes start at 0\n",
        "negative indices count backwards from the end\n",
        "colons, :, are used for slices start:stop:step"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kg4B58knCR5P",
        "outputId": "dd0c0a17-19a1-403a-dbb6-970b3df108bc"
      },
      "source": [
        "rank_1_tensor = tf.constant([0, 1, 1, 2, 3, 5, 8, 13, 21, 34])\n",
        "print(rank_1_tensor.numpy())"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 0  1  1  2  3  5  8 13 21 34]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "obw5_VaNCVPI"
      },
      "source": [
        "**Indexing with a scalar removes the dimension:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jh6lkmGxCVZB",
        "outputId": "a001af75-871a-4cf5-ee4c-09e04b9f13dd"
      },
      "source": [
        "print(\"First:\", rank_1_tensor[0].numpy())\n",
        "print(\"Second:\", rank_1_tensor[1].numpy())\n",
        "print(\"Last:\", rank_1_tensor[-1].numpy())"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "First: 0\n",
            "Second: 1\n",
            "Last: 34\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cR8noAQvCbXF"
      },
      "source": [
        "**Indexing with a : slice keeps the dimension:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aiKTcvkJCbeI",
        "outputId": "547e4da4-44c5-4017-9f83-4ea1ada59187"
      },
      "source": [
        "print(\"Everything:\", rank_1_tensor[:].numpy())\n",
        "print(\"Before 4:\", rank_1_tensor[:4].numpy())\n",
        "print(\"From 4 to the end:\", rank_1_tensor[4:].numpy())\n",
        "print(\"From 2, before 7:\", rank_1_tensor[2:7].numpy())\n",
        "print(\"Every other item:\", rank_1_tensor[::2].numpy())\n",
        "print(\"Reversed:\", rank_1_tensor[::-1].numpy())"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Everything: [ 0  1  1  2  3  5  8 13 21 34]\n",
            "Before 4: [0 1 1 2]\n",
            "From 4 to the end: [ 3  5  8 13 21 34]\n",
            "From 2, before 7: [1 2 3 5 8]\n",
            "Every other item: [ 0  1  3  8 21]\n",
            "Reversed: [34 21 13  8  5  3  2  1  1  0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wRmICBN-CjbU"
      },
      "source": [
        "### **Multi-axis indexing**\n",
        "\n",
        "Higher rank tensors are indexed by passing multiple indices.\n",
        "\n",
        "The single-axis exact same rules as in the single-axis case apply to each axis independently."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F0kK7yxZCofw",
        "outputId": "b6023210-a54c-4f80-ff9c-b9977b2265a9"
      },
      "source": [
        "print(rank_2_tensor.numpy())"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1. 2.]\n",
            " [3. 4.]\n",
            " [5. 6.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "scCer4pZCtQQ"
      },
      "source": [
        "**Passing an integer for each index the result is a scalar.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WUUmKyx1CtYc",
        "outputId": "6d404ecb-dec7-420b-b0cf-75c32771a7b4"
      },
      "source": [
        "# Pull out a single value from a 2-rank tensor\n",
        "print(rank_2_tensor[1, 1].numpy())"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nD1iVpj7Ctf9"
      },
      "source": [
        "**You can index using any combination integers and slices:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XngWv5NzCtoC",
        "outputId": "33ea80ae-4929-4cd3-ca46-5c792d60037b"
      },
      "source": [
        "# Get row and column tensors\n",
        "print(\"Second row:\", rank_2_tensor[1, :].numpy())\n",
        "print(\"Second column:\", rank_2_tensor[:, 1].numpy())\n",
        "print(\"Last row:\", rank_2_tensor[-1, :].numpy())\n",
        "print(\"First item in last column:\", rank_2_tensor[0, -1].numpy())\n",
        "print(\"Skip the first row:\")\n",
        "print(rank_2_tensor[1:, :].numpy(), \"\\n\")"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Second row: [3. 4.]\n",
            "Second column: [2. 4. 6.]\n",
            "Last row: [5. 6.]\n",
            "First item in last column: 2.0\n",
            "Skip the first row:\n",
            "[[3. 4.]\n",
            " [5. 6.]] \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ftMQMpT2DBva"
      },
      "source": [
        "**Here is an example with a 3-axis tensor:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "keum4kK2DFUf",
        "outputId": "1106ffe3-4d44-418b-fdd0-d1baf122e8ca"
      },
      "source": [
        "print(rank_3_tensor[:, :, 4])"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[ 4  9]\n",
            " [14 19]\n",
            " [24 29]], shape=(3, 2), dtype=int32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rd7GhdYkDZtQ"
      },
      "source": [
        "<img src = \"https://raw.githubusercontent.com/mhuzaifadev/ml_zero_to_hero/master/rank3.png?token=AMSGSQ5OYWLJ3UA2MQUAQCC72YFLO\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LOJEUbqZDiva"
      },
      "source": [
        "## **Manipulating Shapes**\n",
        "\n",
        "Reshaping a tensor is of great utility. \n",
        "\n",
        "The `tf.reshape` operation is fast and cheap as the underlying data does not need to be duplicated."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d558p1uGDmyk",
        "outputId": "bfe0e7d3-1b87-4467-dbc5-eb20d7a7a7e9"
      },
      "source": [
        "# Shape returns a `TensorShape` object that shows the size on each dimension\n",
        "var_x = tf.Variable(tf.constant([[1], [2], [3]]))\n",
        "print(var_x.shape)"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(3, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G_ocJiOzDtnw",
        "outputId": "a15ca846-d877-4dd6-ae38-2878e22c068e"
      },
      "source": [
        "# You can convert this object into a Python list, too\n",
        "print(var_x.shape.as_list())"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[3, 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "esBMCLPnDxrQ"
      },
      "source": [
        "**You can reshape a tensor into a new shape. Reshaping is fast and cheap as the underlying data does not need to be duplicated.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aKsvSW7eDzNi"
      },
      "source": [
        "# We can reshape a tensor to a new shape.\n",
        "# Note that we're passing in a list\n",
        "reshaped = tf.reshape(\n",
        "    var_x, [1,3]\n",
        ")"
      ],
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mr4NIh5_FTMq",
        "outputId": "581ce6bd-c482-4de3-d7fe-5de6dc432540"
      },
      "source": [
        "print(var_x.shape)\n",
        "print(reshaped.shape)"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(3, 1)\n",
            "(1, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ZqAEYGVFYbc"
      },
      "source": [
        "The data maintains it's layout in memory and a new tensor is created, with the requested shape, pointing to the same data. TensorFlow uses C-style \"row-major\" memory ordering, where incrementing the right-most index corresponds to a single step in memory."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1t2NKCQhFbYg",
        "outputId": "17d9d070-2586-4c32-b379-bad043f6d485"
      },
      "source": [
        "print(rank_3_tensor)"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[[ 0  1  2  3  4]\n",
            "  [ 5  6  7  8  9]]\n",
            "\n",
            " [[10 11 12 13 14]\n",
            "  [15 16 17 18 19]]\n",
            "\n",
            " [[20 21 22 23 24]\n",
            "  [25 26 27 28 29]]], shape=(3, 2, 5), dtype=int32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vOWQyNH3Fgp3"
      },
      "source": [
        "If you flatten a tensor you can see what order it is laid out in memory."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NjffQkgCFihA",
        "outputId": "dd7a7e8c-e857-4211-8ec7-3d63e67c9cdb"
      },
      "source": [
        "# A `-1` passed in the `shape` argument says \"Whatever fits\".\n",
        "print(tf.reshape(rank_3_tensor, [-1]))"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
            " 24 25 26 27 28 29], shape=(30,), dtype=int32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yoJZvjvbFn4D"
      },
      "source": [
        "Typically the only reasonable uses of `tf.reshape` are to combine or split adjacent axes (or add/remove `1`s).\n",
        "\n",
        "For this 3x2x5 tensor, reshaping to (3x2)x5 or 3x(2x5) are both reasonable things to do, as the slices do not mix:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "COeVVOb8Fpyd",
        "outputId": "5c595fc7-e9e5-40eb-8b1f-9c9fbd517190"
      },
      "source": [
        "print(tf.reshape(rank_3_tensor, [3*2, 5]), \"\\n\")\n",
        "print(tf.reshape(rank_3_tensor, [3, -1]))"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[ 0  1  2  3  4]\n",
            " [ 5  6  7  8  9]\n",
            " [10 11 12 13 14]\n",
            " [15 16 17 18 19]\n",
            " [20 21 22 23 24]\n",
            " [25 26 27 28 29]], shape=(6, 5), dtype=int32) \n",
            "\n",
            "tf.Tensor(\n",
            "[[ 0  1  2  3  4  5  6  7  8  9]\n",
            " [10 11 12 13 14 15 16 17 18 19]\n",
            " [20 21 22 23 24 25 26 27 28 29]], shape=(3, 10), dtype=int32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PrSfJuVUF_F4"
      },
      "source": [
        "<img src = \"https://raw.githubusercontent.com/mhuzaifadev/ml_zero_to_hero/master/concepts.png?token=AMSGSQ7X25ZVGQYBXNR4J7272YGWE\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rBgDJCKQGCq0"
      },
      "source": [
        "Reshaping will \"work\" for any new shape with the same total number of elements, but it will not do anything useful if you do not respect the order of the axes.\n",
        "\n",
        "Swapping axes in `tf.reshape` does not work, you need `tf.transpose` for that. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WBRGwUl5HECc"
      },
      "source": [
        "## **Broadcasting**\n",
        "\n",
        "Broadcasting is a concept borrowed from the equivalent feature in NumPy. In short, under certain conditions, smaller tensors are \"stretched\" automatically to fit larger tensors when running combined operations on them.\n",
        "\n",
        "The simplest and most common case is when you attempt to multiply or add a tensor to a scalar. In that case, the scalar is broadcast to be the same shape as the other argument."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PPe6adxOGHSC",
        "outputId": "059dfe24-882d-48cf-9432-7fb19aa65a3c"
      },
      "source": [
        "x = tf.constant([1, 2, 3])\n",
        "\n",
        "y = tf.constant(2)\n",
        "z = tf.constant([2, 2, 2])\n",
        "# All of these are the same computation\n",
        "print(tf.multiply(x, 2))\n",
        "print(x * y)\n",
        "print(x * z)"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor([2 4 6], shape=(3,), dtype=int32)\n",
            "tf.Tensor([2 4 6], shape=(3,), dtype=int32)\n",
            "tf.Tensor([2 4 6], shape=(3,), dtype=int32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nSUdF0lZHrDp"
      },
      "source": [
        "Likewise, 1-sized dimensions can be stretched out to match the other arguments. Both arguments can be stretched in the same computation.\n",
        "\n",
        "In this case a 3x1 matrix is element-wise multiplied by a 1x4 matrix to produce a 3x4 matrix. Note how the leading 1 is optional: The shape of y is [4]."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3UyCt6qMHuAz",
        "outputId": "4104286d-fc7a-4ef8-e4a4-c775010df08f"
      },
      "source": [
        "# These are the same computations\n",
        "x = tf.reshape(x,[3,1])\n",
        "y = tf.range(1, 5)\n",
        "print(x, \"\\n\")\n",
        "print(y, \"\\n\")\n",
        "print(tf.multiply(x, y))"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[1]\n",
            " [2]\n",
            " [3]], shape=(3, 1), dtype=int32) \n",
            "\n",
            "tf.Tensor([1 2 3 4], shape=(4,), dtype=int32) \n",
            "\n",
            "tf.Tensor(\n",
            "[[ 1  2  3  4]\n",
            " [ 2  4  6  8]\n",
            " [ 3  6  9 12]], shape=(3, 4), dtype=int32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-V-eeRYWIPdb"
      },
      "source": [
        "<img src = \"https://raw.githubusercontent.com/mhuzaifadev/ml_zero_to_hero/master/broadcast.png?token=AMSGSQ7YSMKFTZ4Y4FTU4IK72YH2C\">\n",
        "\n",
        "\n",
        "\n",
        "Here is the same operation without broadcasting:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dqzkJDVEIUJy",
        "outputId": "fb5922b6-8abd-4a37-9214-5e4928e45508"
      },
      "source": [
        "x_stretch = tf.constant([[1, 1, 1, 1],\n",
        "                         [2, 2, 2, 2],\n",
        "                         [3, 3, 3, 3]])\n",
        "\n",
        "y_stretch = tf.constant([[1, 2, 3, 4],\n",
        "                         [1, 2, 3, 4],\n",
        "                         [1, 2, 3, 4]])\n",
        "\n",
        "print(x_stretch * y_stretch)  # Again, operator overloading"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[ 1  2  3  4]\n",
            " [ 2  4  6  8]\n",
            " [ 3  6  9 12]], shape=(3, 4), dtype=int32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A4DCP9khIceL"
      },
      "source": [
        "Most of the time, broadcasting is both time and space efficient, as the broadcast operation never materializes the expanded tensors in memory.\n",
        "\n",
        "You see what broadcasting looks like using `tf.broadcast_to.`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pRUGKYf_Ijn0",
        "outputId": "0742de30-94d7-4a29-9af3-5e3f28cbb178"
      },
      "source": [
        "print(tf.broadcast_to(tf.constant([1, 2, 3]), [3, 3]))"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[1 2 3]\n",
            " [1 2 3]\n",
            " [1 2 3]], shape=(3, 3), dtype=int32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5-xjjDdLIr-F"
      },
      "source": [
        "Unlike a mathematical op, for example, `broadcast_to` does nothing special to save memory. Here, you are materializing the tensor."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S_Xki5rg2E36"
      },
      "source": [
        "**This is it for today**"
      ]
    }
  ]
}